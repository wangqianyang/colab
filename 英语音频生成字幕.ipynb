{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "8ngEr78yNJv0",
        "70615750"
      ],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM+nozcaTFIERmTW7vXSD3U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wangqianyang/colab/blob/main/%E8%8B%B1%E8%AF%AD%E9%9F%B3%E9%A2%91%E7%94%9F%E6%88%90%E5%AD%97%E5%B9%95.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## æ­¥éª¤ä¸€ï¼šç”ŸæˆSRTå­—å¹•"
      ],
      "metadata": {
        "id": "d41k-vn4eGx0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78eJ1c3GIQU3"
      },
      "outputs": [],
      "source": [
        "# å®‰è£… faster-whisperï¼ˆæ›´å¿«ã€æ›´çœæ˜¾å­˜ï¼‰å’Œ ffmpeg\n",
        "!pip install -q faster-whisper\n",
        "!apt-get install -y ffmpeg -qq"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ä¸Šä¼ æ–‡ä»¶"
      ],
      "metadata": {
        "id": "Sbb-hZT-IgSm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# ä¸Šä¼ ä½ çš„éŸ³é¢‘æ–‡ä»¶ï¼ˆæ”¯æŒ mp3, wav, m4a, mp4 ç­‰å¸¸è§æ ¼å¼ï¼‰\n",
        "uploaded = files.upload()\n",
        "\n",
        "# è·å–ä¸Šä¼ çš„æ–‡ä»¶åï¼ˆå‡è®¾åªä¸Šä¼ ä¸€ä¸ªéŸ³é¢‘æ–‡ä»¶ï¼‰\n",
        "audio_file = list(uploaded.keys())[0]\n",
        "print(f\"å·²ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶ï¼š{audio_file}\")"
      ],
      "metadata": {
        "id": "RxWzLnWuIjl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### åŠ è½½æ¨¡å‹å¹¶è½¬å½•ï¼Œç”Ÿæˆ SRT å­—å¹•"
      ],
      "metadata": {
        "id": "V7fBLpBjIyx_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from faster_whisper import WhisperModel\n",
        "import datetime\n",
        "import os\n",
        "\n",
        "# æ¨¡å‹è®¾ç½®ï¼ˆå¦‚æœ large-v3 æ˜¾å­˜ä¸å¤Ÿï¼Œæ”¹æˆ \"medium\"ï¼‰\n",
        "model_size = \"large-v3\"  # è¯•è¯• \"medium\" æˆ– \"small\" å¦‚æœæŠ¥é”™\n",
        "\n",
        "model = WhisperModel(model_size, device=\"cuda\", compute_type=\"float16\")\n",
        "\n",
        "# å…³é”®ä¿®æ”¹ï¼šå…³é—­ VAD è¿‡æ»¤ + è‡ªåŠ¨æ£€æµ‹è¯­è¨€ + é™ä½é˜ˆå€¼\n",
        "segments_iterator, info = model.transcribe(\n",
        "    audio_file,\n",
        "    language=None,          # è‡ªåŠ¨æ£€æµ‹è¯­è¨€ï¼ˆå¾ˆé‡è¦ï¼ï¼‰\n",
        "    beam_size=5,\n",
        "    vad_filter=False,       # å…ˆå…³é—­ VADï¼Œé¿å…è¿‡åº¦è¿‡æ»¤\n",
        "    vad_parameters=dict(min_silence_duration_ms=500),  # å³ä½¿å¼€ VAD ä¹Ÿæ”¾å®½\n",
        "    word_timestamps=True,\n",
        "    temperature=0.0,        # æ›´ç¡®å®šæ€§è¾“å‡º\n",
        "    no_speech_threshold=0.6,  # é»˜è®¤ 0.6ï¼Œè°ƒä½åˆ° 0.4 å¯ä»¥æ›´æ•æ„Ÿï¼ˆå¦‚æœä»ç©ºå†è¯•ï¼‰\n",
        ")\n",
        "\n",
        "# å°† segments è¿­ä»£å™¨è½¬æ¢ä¸ºåˆ—è¡¨ï¼Œä»¥ä¾¿å¤šæ¬¡ä½¿ç”¨\n",
        "segments = list(segments_iterator)\n",
        "\n",
        "# === è¯Šæ–­ä¿¡æ¯è¾“å‡º ===\n",
        "print(f\"æ£€æµ‹åˆ°è¯­è¨€: {info.language} (æ¦‚ç‡: {info.language_probability:.2f})\")\n",
        "print(f\"è½¬å½•æ—¶é•¿: {info.duration:.2f} ç§’\")\n",
        "print(f\"æ£€æµ‹åˆ°æ®µè½æ•°é‡: {len(segments)}\") # ä½¿ç”¨å·²è½¬æ¢ä¸ºåˆ—è¡¨çš„ segments\n",
        "\n",
        "if info.language_probability < 0.5:\n",
        "    print(\"è­¦å‘Šï¼šè¯­è¨€æ£€æµ‹ç½®ä¿¡åº¦ä½ï¼Œå¯èƒ½æ˜¯éè¯­éŸ³å†…å®¹æˆ–å™ªéŸ³ã€‚\")\n",
        "\n",
        "if len(segments) == 0: # ä½¿ç”¨å·²è½¬æ¢ä¸ºåˆ—è¡¨çš„ segments\n",
        "    print(\"é”™è¯¯ï¼šæ²¡æœ‰æ£€æµ‹åˆ°ä»»ä½•è¯­éŸ³æ®µè½ï¼å¯èƒ½åŸå› ï¼š\")\n",
        "    print(\"  - éŸ³é¢‘æ— å£°æˆ–åªæœ‰èƒŒæ™¯éŸ³ä¹\")\n",
        "    print(\"  - æ–‡ä»¶æŸå\")\n",
        "    print(\"  - éœ€è¦æ›´ä½çš„ no_speech_thresholdï¼ˆè¯•è¯• 0.4ï¼‰\")\n",
        "    print(\"  - å°è¯•å…³é—­ vad_filter æˆ–æ¢å°æ¨¡å‹\")\n",
        "else:\n",
        "    print(\"æˆåŠŸæ£€æµ‹åˆ°è¯­éŸ³ï¼\")\n",
        "\n",
        "# å¦‚æœæœ‰æ®µè½ï¼Œæ‰ç”Ÿæˆ SRT\n",
        "if len(segments) > 0: # ä½¿ç”¨å·²è½¬æ¢ä¸ºåˆ—è¡¨çš„ segments\n",
        "    def format_timestamp(seconds: float):\n",
        "        td = datetime.timedelta(seconds=seconds)\n",
        "        hours, remainder = divmod(td.total_seconds(), 3600)\n",
        "        minutes, seconds = divmod(remainder, 60)\n",
        "        milliseconds = int((seconds - int(seconds)) * 1000)\n",
        "        return f\"{int(hours):02}:{int(minutes):02}:{int(seconds):02},{milliseconds:03}\"\n",
        "\n",
        "    srt_content = \"\"\n",
        "    for i, segment in enumerate(segments, start=1): # ä½¿ç”¨å·²è½¬æ¢ä¸ºåˆ—è¡¨çš„ segments\n",
        "        start_time = format_timestamp(segment.start)\n",
        "        end_time = format_timestamp(segment.end)\n",
        "        text = segment.text.strip()\n",
        "        srt_content += f\"{i}\\n{start_time} --> {end_time}\\n{text}\\n\\n\"\n",
        "\n",
        "    srt_filename = os.path.splitext(audio_file)[0] + \".srt\"\n",
        "    with open(srt_filename, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(srt_content)\n",
        "\n",
        "    print(f\"SRT å­—å¹•å·²ä¿å­˜ä¸ºï¼š{srt_filename}\")\n",
        "    files.download(srt_filename)\n",
        "else:\n",
        "    print(\"ç”±äºæ²¡æœ‰æ£€æµ‹åˆ°è¯­éŸ³ï¼ŒSRT æ–‡ä»¶æœªç”Ÿæˆã€‚\")\n",
        "\n",
        "# å§‹ç»ˆé¢„è§ˆè¯Šæ–­ï¼ˆå³ä½¿ä¸ºç©ºï¼‰\n",
        "print(\"\\n=== é¢å¤–è°ƒè¯•ï¼šå°è¯•æ‰“å°åŸå§‹ info ===\")\n",
        "print(info)\n"
      ],
      "metadata": {
        "id": "cNEb7t9aI1Fa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ï¼ˆå¯é€‰ï¼‰ï¼šé¢„è§ˆå‰å‡ è¡Œå­—å¹•"
      ],
      "metadata": {
        "id": "HMfGgW7_JpKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# æ‰“å°å‰ 10 æ®µå­—å¹•é¢„è§ˆ\n",
        "print(\"\\n=== å‰ 10 æ®µå­—å¹•é¢„è§ˆ ===\\n\")\n",
        "preview_segments = list(segments)[:10]\n",
        "for i, segment in enumerate(preview_segments, start=1):\n",
        "    print(f\"{i}\\n{format_timestamp(segment.start)} --> {format_timestamp(segment.end)}\\n{segment.text.strip()}\\n\")"
      ],
      "metadata": {
        "id": "PKmgrdk0Jq3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## æ­¥éª¤äºŒï¼šAIè¯†åˆ«é‡ç‚¹å¹¶ç”ŸæˆåŒè¯­+æ³¨è§£"
      ],
      "metadata": {
        "id": "xOkPcAhxRyKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: å®‰è£…å¿…è¦åº“ï¼ˆåªéœ€è¿è¡Œä¸€æ¬¡ï¼‰\n",
        "!pip install -q openai pysrt"
      ],
      "metadata": {
        "id": "JNLHDJuDR5jV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: ä¸Šä¼ æˆ–åŠ è½½ä½ çš„ SRT æ–‡ä»¶ï¼ˆå¦‚æœå·²ç»ä¸Šä¼ è¿‡ï¼Œå¯è·³è¿‡ä¸Šä¼ ç›´æ¥æŒ‡å®šæ–‡ä»¶åï¼‰\n",
        "from google.colab import files\n",
        "import pysrt\n",
        "import os\n",
        "\n",
        "# å¦‚æœä½ å·²ç»è¿è¡Œè¿‡ç¬¬ä¸€æ­¥ï¼ŒSRT æ–‡ä»¶åº”è¯¥å·²ç»åœ¨ Colab ç¯å¢ƒä¸­\n",
        "# ç›´æ¥æŒ‡å®šæ–‡ä»¶åï¼ˆæ›¿æ¢æˆä½ çš„å®é™… SRT æ–‡ä»¶åï¼Œä¾‹å¦‚ \"your_audio.srt\"ï¼‰\n",
        "srt_filename = \"001.srt\"  # <--- è¿™é‡Œæ”¹æˆä½ çš„ SRT æ–‡ä»¶å !!!\n",
        "\n",
        "# å¦‚æœæ–‡ä»¶ä¸åœ¨ï¼Œç›´æ¥ä¸Šä¼ \n",
        "if not os.path.exists(srt_filename):\n",
        "    print(\"æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·ä¸Šä¼  SRT æ–‡ä»¶\")\n",
        "    uploaded = files.upload()\n",
        "    srt_filename = list(uploaded.keys())[0]\n",
        "\n",
        "# åŠ è½½ SRT å¹¶æå–çº¯æ–‡æœ¬å¥å­ï¼ˆæŒ‰æ®µè½é¡ºåºï¼‰\n",
        "subs = pysrt.open(srt_filename, encoding='utf-8')\n",
        "\n",
        "# æå–æ¯æ®µçš„çº¯æ–‡æœ¬ï¼ˆå»æ‰æ—¶é—´æˆ³ï¼Œåªä¿ç•™æ–‡å­—ï¼‰\n",
        "sentences = [sub.text.strip().replace('\\n', ' ') for sub in subs if sub.text.strip()]\n",
        "\n",
        "print(f\"æˆåŠŸåŠ è½½ SRTï¼Œå…± {len(sentences)} æ®µå¥å­\")\n",
        "print(\"\\nå‰ 10 å¥é¢„è§ˆï¼š\")\n",
        "for i, sent in enumerate(sentences[:10], 1):\n",
        "    print(f\"{i}: {sent}\")"
      ],
      "metadata": {
        "id": "vWCjT8QVSEuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4410dacf"
      },
      "source": [
        "### ä½¿ç”¨ OpenRouter GPT-OSS æ¨¡å‹ è¯†åˆ«é‡ç‚¹å•è¯å’Œè¯ç»„\n",
        "\n",
        "#### 1. è®¾ç½® OpenRouter API Key\n",
        "\n",
        "æ‚¨éœ€è¦ä¸€ä¸ª OpenRouter API å¯†é’¥ã€‚å¦‚æœè¿˜æ²¡æœ‰ï¼Œè¯·å‰å¾€ [https://openrouter.ai/keys](https://openrouter.ai/keys) åˆ›å»ºä¸€ä¸ªã€‚\n",
        "åœ¨ Colab ä¸­ï¼Œé€šè¿‡å·¦ä¾§é¢æ¿çš„â€œğŸ”‘â€å›¾æ ‡å°†å¯†é’¥æ·»åŠ åˆ° Secrets Managerã€‚å°†å…¶å‘½åä¸º `OPENROUTER_API_KEY`ã€‚ç„¶åä»£ç å°†è‡ªåŠ¨è·å–è¯¥å¯†é’¥ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2398e14c"
      },
      "source": [
        "import getpass\n",
        "from google.colab import userdata\n",
        "\n",
        "# è·å– Colab Secrets ä¸­ä¿å­˜çš„ OPENROUTER_API_KEY\n",
        "OPENROUTER_API_KEY = userdata.get('OPENROUTER_API_KEY')\n",
        "\n",
        "if not OPENROUTER_API_KEY:\n",
        "    print(\"è­¦å‘Šï¼šæœªæ‰¾åˆ° OPENROUTER_API_KEYã€‚è¯·ç¡®ä¿æ‚¨å·²åœ¨ Colab Secrets ä¸­è®¾ç½®å®ƒã€‚\")\n",
        "else:\n",
        "    print(\"OpenRouter API Key å·²è®¾ç½®\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ec4a11db"
      },
      "source": [
        "# Cell 4: å®šä¹‰ Prompt æ¨¡æ¿ + æ‰¹é‡è°ƒç”¨ OpenRouter API\n",
        "import json\n",
        "import time\n",
        "from openai import OpenAI # OpenRouter å…¼å®¹ OpenAI API\n",
        "\n",
        "# ä½¿ç”¨ OpenAI å…¼å®¹æ ¼å¼è°ƒç”¨ OpenRouter API\n",
        "client = OpenAI(\n",
        "    api_key=OPENROUTER_API_KEY,\n",
        "    base_url=\"https://openrouter.ai/api/v1\"\n",
        ")\n",
        "\n",
        "# OpenRouter æ¨¡å‹åç§°\n",
        "model_name = \"openai/gpt-oss-120b:free\"\n",
        "\n",
        "# Prompt æ¨¡æ¿ï¼ˆä¸¥æ ¼å‚è€ƒ BBC / EnglishClass101 é£æ ¼ï¼‰\n",
        "prompt_template = \"\"\"\n",
        "ä½ æ˜¯è‹±è¯­å­¦ä¹ å­—å¹•ä¸“å®¶ï¼Œå‚è€ƒBBC Learning Englishã€English Addict with Mr Steveå’ŒEnglishClass101çš„å­—å¹•é£æ ¼ã€‚\n",
        "ä¸ºæ¯å¥è‹±æ–‡è¾“å‡ºï¼š\n",
        "1. è‹±æ–‡åŸæ–‡ï¼šé‡ç‚¹å•è¯/çŸ­è¯­ç”¨[HL:yellow]æ ‡è®°ï¼ˆç”Ÿè¯/é«˜é¢‘æ–°è¯ï¼‰ï¼Œä¹ è¯­/æ­é…ç”¨[HL:red]æ ‡è®°ã€‚\n",
        "2. ä¸­æ–‡ç¿»è¯‘ï¼šè‡ªç„¶æµç•…ã€é€‚åˆå­¦ä¹ è€…ã€‚\n",
        "3. æ³¨è§£è¡Œï¼ˆå¯é€‰ï¼‰ï¼šä»…å¯¹é‡ç‚¹è¯æ·»åŠ ç®€çŸ­æ‹¬å·è§£é‡Šï¼Œå¦‚ (run into = å¶é‡ï¼Œmeet by chance)ã€‚æ³¨è§£è¦æç®€ï¼Œåªå‡ºç°å¿…è¦æ—¶ã€‚\n",
        "\n",
        "è¾“å‡ºä¸¥æ ¼ä¸º JSON æ•°ç»„ï¼ˆæ— éœ€å…¶ä»–æ–‡å­—ï¼‰ï¼Œæ¯ä¸ªå¯¹è±¡å¯¹åº”ä¸€å¥ï¼š\n",
        "[\n",
        "  {{\n",
        "    \"english\": \"æ ‡è®°åçš„è‹±æ–‡\",\n",
        "    \"chinese\": \"ä¸­æ–‡ç¿»è¯‘\",\n",
        "    \"annotation\": \"æ³¨è§£ï¼ˆå¦‚æœæ²¡æœ‰åˆ™ä¸ºç©ºå­—ç¬¦ä¸² \"\"ï¼‰\"\n",
        "  }},\n",
        "  ...\n",
        "]\n",
        "\n",
        "ç°åœ¨å¤„ç†ä»¥ä¸‹å¥å­ï¼ˆæ¯å¥ç”¨æ•°å­—ç¼–å·ï¼‰ï¼š\n",
        "{numbered_sentences}\n",
        "\n",
        "åªè¾“å‡º JSONï¼\n",
        "\"\"\"\n",
        "\n",
        "# æ‰¹é‡å¤§å°ï¼ˆå»ºè®® 8-12 å¥ä¸€æ‰¹ï¼Œé¿å…è¶…è¿‡ token é™åˆ¶ï¼‰\n",
        "batch_size = 10\n",
        "\n",
        "enhanced_data = []\n",
        "\n",
        "print(\"å¼€å§‹æ‰¹é‡è°ƒç”¨ OpenRouter API å¤„ç†...\")\n",
        "for i in range(0, len(sentences), batch_size):\n",
        "    batch = sentences[i:i+batch_size]\n",
        "\n",
        "    # ç¼–å·æ˜¾ç¤º\n",
        "    numbered = \"\\n\".join(f\"{j+1}: {sent}\" for j, sent in enumerate(batch))\n",
        "\n",
        "    prompt = prompt_template.format(numbered_sentences=numbered)\n",
        "\n",
        "    print(f\"å¤„ç†ç¬¬ {i+1}-{min(i+batch_size, len(sentences))} å¥ï¼ˆå…± {len(batch)} å¥ï¼‰...\")\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=model_name,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0.3,      # ä½æ¸©åº¦æ›´ç¨³å®š\n",
        "            max_tokens=4096\n",
        "        )\n",
        "\n",
        "        content = response.choices[0].message.content.strip()\n",
        "\n",
        "        # å°è¯•è§£æ JSON\n",
        "        try:\n",
        "            batch_json = json.loads(content)\n",
        "        except json.JSONDecodeError:\n",
        "            print(\"JSON è§£æå¤±è´¥ï¼ŒåŸå§‹è¾“å‡ºï¼š\")\n",
        "            print(content)\n",
        "            print(\"è¯·æ‰‹åŠ¨ä¿®æ­£æˆ–é‡æ–°è¿è¡Œæœ¬æ‰¹\")\n",
        "            continue\n",
        "\n",
        "        enhanced_data.extend(batch_json)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"API è°ƒç”¨å‡ºé”™ï¼š{e}\")\n",
        "        print(\"å¯èƒ½åŸå› ï¼šAPI Key æ— æ•ˆã€é…é¢ä¸è¶³ã€ç½‘ç»œé—®é¢˜\")\n",
        "        break\n",
        "\n",
        "    # ç¤¼è²Œç­‰å¾…ï¼Œé¿å…è§¦å‘é™æµ\n",
        "    time.sleep(2)\n",
        "\n",
        "print(f\"\\nå¤„ç†å®Œæˆï¼å…±å¢å¼º {len(enhanced_data)} æ®µ\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: ä¿å­˜å¢å¼º JSON å¹¶ä¸‹è½½\n",
        "import json\n",
        "from google.colab import files\n",
        "\n",
        "json_filename = os.path.splitext(srt_filename)[0] + \"_enhanced.json\"\n",
        "\n",
        "with open(json_filename, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(enhanced_data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"å¢å¼º JSON å·²ä¿å­˜ä¸ºï¼š{json_filename}\")\n",
        "print(\"\\nå‰ 3 æ¡é¢„è§ˆï¼š\")\n",
        "print(json.dumps(enhanced_data[:3], ensure_ascii=False, indent=2))\n",
        "\n",
        "# è‡ªåŠ¨ä¸‹è½½\n",
        "files.download(json_filename)"
      ],
      "metadata": {
        "id": "j-ev4Da4Z5aA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## æ­¥éª¤ä¸‰ï¼šè‡ªåŠ¨ç”ŸæˆASSå­—å¹•ï¼ˆå…¨è‡ªåŠ¨ï¼ŒPythonè„šæœ¬ï¼‰"
      ],
      "metadata": {
        "id": "KeCVwtIeamhz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pysrt\n",
        "import json\n",
        "import re\n",
        "\n",
        "# åŠ è½½åŸSRTï¼ˆæ—¶é—´è½´ï¼‰\n",
        "subs = pysrt.open(srt_filename)\n",
        "\n",
        "# åŠ è½½AIå¤„ç†çš„JSON\n",
        "with open(json_filename, 'r', encoding='utf-8') as f:\n",
        "    enhanced = json.load(f)\n",
        "\n",
        "# ASSé¢œè‰²å®šä¹‰\n",
        "colors = {\n",
        "    'yellow': '&H00FFFF&',   # ASSé»„è‰²\n",
        "    'orange': '&H00A5FF&',\n",
        "    'red': '&H0000FF&',\n",
        "    'white': '&HFFFFFF&'\n",
        "}\n",
        "\n",
        "def add_color(text):\n",
        "    # æ›¿æ¢[HL:color]ä¸ºASSæ ‡ç­¾\n",
        "    def repl(match):\n",
        "        word = match.group(1)\n",
        "        color = colors.get(match.group(2), colors['white'])\n",
        "        return f'{{\\\\c{color}}}{word}{{\\\\c{colors[\"white\"]}}}'\n",
        "    return re.sub(r'\\[HL:(\\w+?)\\](.*?)\\[/HL\\]', repl, text)\n",
        "\n",
        "# åˆå¹¶\n",
        "for i, sub in enumerate(subs):\n",
        "    item = enhanced[i]\n",
        "    english = add_color(item['english'])\n",
        "    chinese = item['chinese']\n",
        "    annotation = item.get('annotation', '')\n",
        "    # ASSä¸‰è¡Œå¸ƒå±€\n",
        "    sub.text = f\"{english}\\\\N{{\\\\fs20}}{chinese}\\\\N{{\\\\fs18\\\\c&H808080&}}{annotation}\"\n",
        "\n",
        "# ä¿å­˜ASS\n",
        "with open('final.ass', 'w', encoding='utf-8') as f:\n",
        "    f.write('[Script Info]\\nScriptType: v4.00+\\n\\n[V4+ Styles]\\nFormat: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding\\nStyle: Default,Arial,28,&H00FFFFFF,&H000000FF,&H00000000,&H00000000,0,0,0,0,100,100,0,0,1,2,2,2,10,10,30,1\\n\\n[Events]\\nFormat: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text\\n')\n",
        "    for sub in subs:\n",
        "        f.write(f'Dialogue: 0,{sub.start},{sub.end},Default,,0,0,0,,{sub.text}\\n')\n",
        "\n",
        "print(\"ASSå­—å¹•ç”Ÿæˆå®Œæˆï¼\")"
      ],
      "metadata": {
        "id": "rmYkgZ_9arj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ã€è°ƒè¯•ç”¨ï¼Œä¸æ‰§è¡Œã€‘ä¸‹è½½youtubeçš„éŸ³é¢‘è¯•è¯•"
      ],
      "metadata": {
        "id": "8ngEr78yNJv0"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e12ad949"
      },
      "source": [
        "# å®‰è£… yt-dlp\n",
        "!pip install -q yt-dlp\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74bcba22"
      },
      "source": [
        "import yt_dlp\n",
        "import os\n",
        "\n",
        "def download_youtube_audio(youtube_url):\n",
        "    ydl_opts = {\n",
        "        'format': 'bestaudio/best',\n",
        "        'postprocessors': [{\n",
        "            'key': 'FFmpegExtractAudio',\n",
        "            'preferredcodec': 'mp3',\n",
        "            'preferredquality': '192',\n",
        "        }],\n",
        "        'outtmpl': '%(title)s.%(ext)s', # Output filename template\n",
        "        'quiet': True, # Suppress console output for cleaner execution\n",
        "        'no_warnings': True,\n",
        "    }\n",
        "    try:\n",
        "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "            info_dict = ydl.extract_info(youtube_url, download=True)\n",
        "            filename = ydl.prepare_filename(info_dict)\n",
        "            # Change extension to mp3 explicitly\n",
        "            base, ext = os.path.splitext(filename)\n",
        "            mp3_filename = base + '.mp3'\n",
        "            print(f\"æˆåŠŸä¸‹è½½éŸ³é¢‘ï¼š{mp3_filename}\")\n",
        "            return mp3_filename\n",
        "    except Exception as e:\n",
        "        print(f\"ä¸‹è½½å¤±è´¥ï¼š{e}\")\n",
        "        return None\n",
        "\n",
        "# ç¤ºä¾‹ç”¨æ³•ï¼š\n",
        "# youtube_url = 'YOUR_YOUTUBE_URL_HERE'\n",
        "# downloaded_file = download_youtube_audio(youtube_url)\n",
        "# if downloaded_file:\n",
        "#     print(f\"æ–‡ä»¶å·²ä¿å­˜åˆ°ï¼š{downloaded_file}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "youtube_url = 'https://www.youtube.com/watch?v=gHvBLFYNzMc'\n",
        "downloaded_file = download_youtube_audio(youtube_url)\n",
        "if downloaded_file:\n",
        "    print(f\"æ–‡ä»¶å·²ä¿å­˜åˆ°ï¼š{downloaded_file}\")"
      ],
      "metadata": {
        "id": "7ike8-AqNjsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9545ed7"
      },
      "source": [
        "ç°åœ¨ä½ å¯ä»¥ä½¿ç”¨ä¸Šé¢çš„ `download_youtube_audio` å‡½æ•°æ¥ä¸‹è½½YouTubeè§†é¢‘çš„éŸ³é¢‘ã€‚åªéœ€å°†ä½ æƒ³è¦ä¸‹è½½çš„YouTubeé“¾æ¥æ›¿æ¢æ‰ `YOUR_YOUTUBE_URL_HERE` å³å¯ã€‚"
      ]
    }
  ]
}