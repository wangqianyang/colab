{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wangqianyang/colab/blob/main/%E8%8B%B1%E8%AF%AD%E9%9F%B3%E9%A2%91%E7%94%9F%E6%88%90%E5%AD%97%E5%B9%95.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d41k-vn4eGx0"
      },
      "source": [
        "## æ­¥éª¤ä¸€ï¼šç”ŸæˆSRTå­—å¹•"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78eJ1c3GIQU3"
      },
      "outputs": [],
      "source": [
        "# å®‰è£… faster-whisperï¼ˆæ›´å¿«ã€æ›´çœæ˜¾å­˜ï¼‰å’Œ ffmpeg\n",
        "!pip install -q faster-whisper\n",
        "!apt-get install -y ffmpeg -qq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sbb-hZT-IgSm"
      },
      "source": [
        "### ä¸Šä¼ æ–‡ä»¶"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RxWzLnWuIjl4"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# ä¸Šä¼ ä½ çš„éŸ³é¢‘æ–‡ä»¶ï¼ˆæ”¯æŒ mp3, wav, m4a, mp4 ç­‰å¸¸è§æ ¼å¼ï¼‰\n",
        "uploaded = files.upload()\n",
        "\n",
        "# è·å–ä¸Šä¼ çš„æ–‡ä»¶åï¼ˆå‡è®¾åªä¸Šä¼ ä¸€ä¸ªéŸ³é¢‘æ–‡ä»¶ï¼‰\n",
        "audio_file = list(uploaded.keys())[0]\n",
        "print(f\"å·²ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶ï¼š{audio_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7fBLpBjIyx_"
      },
      "source": [
        "### åŠ è½½æ¨¡å‹å¹¶è½¬å½•ï¼Œç”Ÿæˆ SRT å­—å¹•"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNEb7t9aI1Fa"
      },
      "outputs": [],
      "source": [
        "from faster_whisper import WhisperModel\n",
        "import datetime\n",
        "import os\n",
        "\n",
        "# æ¨¡å‹è®¾ç½®ï¼ˆå¦‚æœ large-v3 æ˜¾å­˜ä¸å¤Ÿï¼Œæ”¹æˆ \"medium\"ï¼‰\n",
        "model_size = \"large-v3\"  # è¯•è¯• \"medium\" æˆ– \"small\" å¦‚æœæŠ¥é”™\n",
        "\n",
        "model = WhisperModel(model_size, device=\"cuda\", compute_type=\"float16\")\n",
        "\n",
        "# å…³é”®ä¿®æ”¹ï¼šå…³é—­ VAD è¿‡æ»¤ + è‡ªåŠ¨æ£€æµ‹è¯­è¨€ + é™ä½é˜ˆå€¼\n",
        "segments_iterator, info = model.transcribe(\n",
        "    audio_file,\n",
        "    language=None,          # è‡ªåŠ¨æ£€æµ‹è¯­è¨€ï¼ˆå¾ˆé‡è¦ï¼ï¼‰\n",
        "    beam_size=5,\n",
        "    vad_filter=False,       # å…ˆå…³é—­ VADï¼Œé¿å…è¿‡åº¦è¿‡æ»¤\n",
        "    vad_parameters=dict(min_silence_duration_ms=500),  # å³ä½¿å¼€ VAD ä¹Ÿæ”¾å®½\n",
        "    word_timestamps=True,\n",
        "    temperature=0.0,        # æ›´ç¡®å®šæ€§è¾“å‡º\n",
        "    no_speech_threshold=0.6,  # é»˜è®¤ 0.6ï¼Œè°ƒä½åˆ° 0.4 å¯ä»¥æ›´æ•æ„Ÿï¼ˆå¦‚æœä»ç©ºå†è¯•ï¼‰\n",
        ")\n",
        "\n",
        "# å°† segments è¿­ä»£å™¨è½¬æ¢ä¸ºåˆ—è¡¨ï¼Œä»¥ä¾¿å¤šæ¬¡ä½¿ç”¨\n",
        "segments = list(segments_iterator)\n",
        "\n",
        "# === è¯Šæ–­ä¿¡æ¯è¾“å‡º ===\n",
        "print(f\"æ£€æµ‹åˆ°è¯­è¨€: {info.language} (æ¦‚ç‡: {info.language_probability:.2f})\")\n",
        "print(f\"è½¬å½•æ—¶é•¿: {info.duration:.2f} ç§’\")\n",
        "print(f\"æ£€æµ‹åˆ°æ®µè½æ•°é‡: {len(segments)}\") # ä½¿ç”¨å·²è½¬æ¢ä¸ºåˆ—è¡¨çš„ segments\n",
        "\n",
        "if info.language_probability < 0.5:\n",
        "    print(\"è­¦å‘Šï¼šè¯­è¨€æ£€æµ‹ç½®ä¿¡åº¦ä½ï¼Œå¯èƒ½æ˜¯éè¯­éŸ³å†…å®¹æˆ–å™ªéŸ³ã€‚\")\n",
        "\n",
        "if len(segments) == 0: # ä½¿ç”¨å·²è½¬æ¢ä¸ºåˆ—è¡¨çš„ segments\n",
        "    print(\"é”™è¯¯ï¼šæ²¡æœ‰æ£€æµ‹åˆ°ä»»ä½•è¯­éŸ³æ®µè½ï¼å¯èƒ½åŸå› ï¼š\")\n",
        "    print(\"  - éŸ³é¢‘æ— å£°æˆ–åªæœ‰èƒŒæ™¯éŸ³ä¹\")\n",
        "    print(\"  - æ–‡ä»¶æŸå\")\n",
        "    print(\"  - éœ€è¦æ›´ä½çš„ no_speech_thresholdï¼ˆè¯•è¯• 0.4ï¼‰\")\n",
        "    print(\"  - å°è¯•å…³é—­ vad_filter æˆ–æ¢å°æ¨¡å‹\")\n",
        "else:\n",
        "    print(\"æˆåŠŸæ£€æµ‹åˆ°è¯­éŸ³ï¼\")\n",
        "\n",
        "# å¦‚æœæœ‰æ®µè½ï¼Œæ‰ç”Ÿæˆ SRT\n",
        "if len(segments) > 0: # ä½¿ç”¨å·²è½¬æ¢ä¸ºåˆ—è¡¨çš„ segments\n",
        "    def format_timestamp(seconds: float):\n",
        "        td = datetime.timedelta(seconds=seconds)\n",
        "        hours, remainder = divmod(td.total_seconds(), 3600)\n",
        "        minutes, seconds = divmod(remainder, 60)\n",
        "        milliseconds = int((seconds - int(seconds)) * 1000)\n",
        "        return f\"{int(hours):02}:{int(minutes):02}:{int(seconds):02},{milliseconds:03}\"\n",
        "\n",
        "    srt_content = \"\"\n",
        "    for i, segment in enumerate(segments, start=1): # ä½¿ç”¨å·²è½¬æ¢ä¸ºåˆ—è¡¨çš„ segments\n",
        "        start_time = format_timestamp(segment.start)\n",
        "        end_time = format_timestamp(segment.end)\n",
        "        text = segment.text.strip()\n",
        "        srt_content += f\"{i}\\n{start_time} --> {end_time}\\n{text}\\n\\n\"\n",
        "\n",
        "    srt_filename = os.path.splitext(audio_file)[0] + \".srt\"\n",
        "    with open(srt_filename, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(srt_content)\n",
        "\n",
        "    print(f\"SRT å­—å¹•å·²ä¿å­˜ä¸ºï¼š{srt_filename}\")\n",
        "    files.download(srt_filename)\n",
        "else:\n",
        "    print(\"ç”±äºæ²¡æœ‰æ£€æµ‹åˆ°è¯­éŸ³ï¼ŒSRT æ–‡ä»¶æœªç”Ÿæˆã€‚\")\n",
        "\n",
        "# å§‹ç»ˆé¢„è§ˆè¯Šæ–­ï¼ˆå³ä½¿ä¸ºç©ºï¼‰\n",
        "print(\"\\n=== é¢å¤–è°ƒè¯•ï¼šå°è¯•æ‰“å°åŸå§‹ info ===\")\n",
        "print(info)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMfGgW7_JpKf"
      },
      "source": [
        "### ï¼ˆå¯é€‰ï¼‰ï¼šé¢„è§ˆå‰å‡ è¡Œå­—å¹•"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PKmgrdk0Jq3_"
      },
      "outputs": [],
      "source": [
        "# æ‰“å°å‰ 10 æ®µå­—å¹•é¢„è§ˆ\n",
        "print(\"\\n=== å‰ 10 æ®µå­—å¹•é¢„è§ˆ ===\\n\")\n",
        "preview_segments = list(segments)[:10]\n",
        "for i, segment in enumerate(preview_segments, start=1):\n",
        "    print(f\"{i}\\n{format_timestamp(segment.start)} --> {format_timestamp(segment.end)}\\n{segment.text.strip()}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOkPcAhxRyKW"
      },
      "source": [
        "## æ­¥éª¤äºŒï¼šAIè¯†åˆ«é‡ç‚¹å¹¶ç”ŸæˆåŒè¯­+æ³¨è§£"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JNLHDJuDR5jV"
      },
      "outputs": [],
      "source": [
        "# Cell 1: å®‰è£…å¿…è¦åº“ï¼ˆåªéœ€è¿è¡Œä¸€æ¬¡ï¼‰\n",
        "!pip install -q openai pysrt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWCjT8QVSEuO"
      },
      "outputs": [],
      "source": [
        "# Cell 2: ä¸Šä¼ æˆ–åŠ è½½ä½ çš„ SRT æ–‡ä»¶ï¼ˆå¦‚æœå·²ç»ä¸Šä¼ è¿‡ï¼Œå¯è·³è¿‡ä¸Šä¼ ç›´æ¥æŒ‡å®šæ–‡ä»¶åï¼‰\n",
        "from google.colab import files\n",
        "import pysrt\n",
        "import os\n",
        "\n",
        "# å¦‚æœä½ å·²ç»è¿è¡Œè¿‡ç¬¬ä¸€æ­¥ï¼ŒSRT æ–‡ä»¶åº”è¯¥å·²ç»åœ¨ Colab ç¯å¢ƒä¸­\n",
        "# ç›´æ¥æŒ‡å®šæ–‡ä»¶åï¼ˆæ›¿æ¢æˆä½ çš„å®é™… SRT æ–‡ä»¶åï¼Œä¾‹å¦‚ \"your_audio.srt\"ï¼‰\n",
        "srt_filename = \"001.srt\"  # <--- è¿™é‡Œæ”¹æˆä½ çš„ SRT æ–‡ä»¶å !!!\n",
        "\n",
        "# å¦‚æœæ–‡ä»¶ä¸åœ¨ï¼Œç›´æ¥ä¸Šä¼ \n",
        "if not os.path.exists(srt_filename):\n",
        "    print(\"æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·ä¸Šä¼  SRT æ–‡ä»¶\")\n",
        "    uploaded = files.upload()\n",
        "    srt_filename = list(uploaded.keys())[0]\n",
        "\n",
        "# åŠ è½½ SRT å¹¶æå–çº¯æ–‡æœ¬å¥å­ï¼ˆæŒ‰æ®µè½é¡ºåºï¼‰\n",
        "subs = pysrt.open(srt_filename, encoding='utf-8')\n",
        "\n",
        "# æå–æ¯æ®µçš„çº¯æ–‡æœ¬ï¼ˆå»æ‰æ—¶é—´æˆ³ï¼Œåªä¿ç•™æ–‡å­—ï¼‰\n",
        "sentences = [sub.text.strip().replace('\\n', ' ') for sub in subs if sub.text.strip()]\n",
        "\n",
        "print(f\"æˆåŠŸåŠ è½½ SRTï¼Œå…± {len(sentences)} æ®µå¥å­\")\n",
        "print(\"\\nå‰ 10 å¥é¢„è§ˆï¼š\")\n",
        "for i, sent in enumerate(sentences[:10], 1):\n",
        "    print(f\"{i}: {sent}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4410dacf"
      },
      "source": [
        "### ä½¿ç”¨ OpenRouter GPT-OSS æ¨¡å‹ è¯†åˆ«é‡ç‚¹å•è¯å’Œè¯ç»„\n",
        "\n",
        "#### 1. è®¾ç½® OpenRouter API Key\n",
        "\n",
        "æ‚¨éœ€è¦ä¸€ä¸ª OpenRouter API å¯†é’¥ã€‚å¦‚æœè¿˜æ²¡æœ‰ï¼Œè¯·å‰å¾€ [https://openrouter.ai/keys](https://openrouter.ai/keys) åˆ›å»ºä¸€ä¸ªã€‚\n",
        "åœ¨ Colab ä¸­ï¼Œé€šè¿‡å·¦ä¾§é¢æ¿çš„â€œğŸ”‘â€å›¾æ ‡å°†å¯†é’¥æ·»åŠ åˆ° Secrets Managerã€‚å°†å…¶å‘½åä¸º `OPENROUTER_API_KEY`ã€‚ç„¶åä»£ç å°†è‡ªåŠ¨è·å–è¯¥å¯†é’¥ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2398e14c"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "from google.colab import userdata\n",
        "\n",
        "# è·å– Colab Secrets ä¸­ä¿å­˜çš„ OPENROUTER_API_KEY\n",
        "OPENROUTER_API_KEY = userdata.get('OPENROUTER_API_KEY')\n",
        "\n",
        "if not OPENROUTER_API_KEY:\n",
        "    print(\"è­¦å‘Šï¼šæœªæ‰¾åˆ° OPENROUTER_API_KEYã€‚è¯·ç¡®ä¿æ‚¨å·²åœ¨ Colab Secrets ä¸­è®¾ç½®å®ƒã€‚\")\n",
        "else:\n",
        "    print(\"OpenRouter API Key å·²è®¾ç½®\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ec4a11db"
      },
      "outputs": [],
      "source": [
        "# Cell 4: å®šä¹‰ Prompt æ¨¡æ¿ + æ‰¹é‡è°ƒç”¨ OpenRouter API\n",
        "import json\n",
        "import time\n",
        "from openai import OpenAI # OpenRouter å…¼å®¹ OpenAI API\n",
        "\n",
        "# ä½¿ç”¨ OpenAI å…¼å®¹æ ¼å¼è°ƒç”¨ OpenRouter API\n",
        "client = OpenAI(\n",
        "    api_key=OPENROUTER_API_KEY,\n",
        "    base_url=\"https://openrouter.ai/api/v1\"\n",
        ")\n",
        "\n",
        "# OpenRouter æ¨¡å‹åç§°\n",
        "model_name = \"openai/gpt-oss-120b:free\"\n",
        "\n",
        "# Prompt æ¨¡æ¿ï¼ˆä¸¥æ ¼å‚è€ƒ BBC / EnglishClass101 é£æ ¼ï¼‰\n",
        "prompt_template = \"\"\"\n",
        "ä½ æ˜¯è‹±è¯­å­¦ä¹ å­—å¹•ä¸“å®¶ï¼Œå‚è€ƒBBC Learning Englishã€English Addict with Mr Steveå’ŒEnglishClass101çš„å­—å¹•é£æ ¼ã€‚\n",
        "ä¸ºæ¯å¥è‹±æ–‡è¾“å‡ºï¼š\n",
        "1. è‹±æ–‡åŸæ–‡ï¼šé‡ç‚¹å•è¯/çŸ­è¯­ç”¨[HL:yellow]æ ‡è®°ï¼ˆç”Ÿè¯/é«˜é¢‘æ–°è¯ï¼‰ï¼Œä¹ è¯­/æ­é…ç”¨[HL:red]æ ‡è®°ã€‚\n",
        "2. ä¸­æ–‡ç¿»è¯‘ï¼šè‡ªç„¶æµç•…ã€é€‚åˆå­¦ä¹ è€…ã€‚\n",
        "3. æ³¨è§£è¡Œï¼ˆå¯é€‰ï¼‰ï¼šä»…å¯¹é‡ç‚¹è¯æ·»åŠ ç®€çŸ­æ‹¬å·è§£é‡Šï¼Œå¦‚ (run into = å¶é‡ï¼Œmeet by chance)ã€‚æ³¨è§£è¦æç®€ï¼Œåªå‡ºç°å¿…è¦æ—¶ã€‚\n",
        "\n",
        "è¾“å‡ºä¸¥æ ¼ä¸º JSON æ•°ç»„ï¼ˆæ— éœ€å…¶ä»–æ–‡å­—ï¼‰ï¼Œæ¯ä¸ªå¯¹è±¡å¯¹åº”ä¸€å¥ï¼š\n",
        "[\n",
        "  {{\n",
        "    \"english\": \"æ ‡è®°åçš„è‹±æ–‡\",\n",
        "    \"chinese\": \"ä¸­æ–‡ç¿»è¯‘\",\n",
        "    \"annotation\": \"æ³¨è§£ï¼ˆå¦‚æœæ²¡æœ‰åˆ™ä¸ºç©ºå­—ç¬¦ä¸² \"\"ï¼‰\"\n",
        "  }},\n",
        "  ...\n",
        "]\n",
        "\n",
        "ç°åœ¨å¤„ç†ä»¥ä¸‹å¥å­ï¼ˆæ¯å¥ç”¨æ•°å­—ç¼–å·ï¼‰ï¼š\n",
        "{numbered_sentences}\n",
        "\n",
        "åªè¾“å‡º JSONï¼\n",
        "\"\"\"\n",
        "\n",
        "# æ‰¹é‡å¤§å°ï¼ˆå»ºè®® 8-12 å¥ä¸€æ‰¹ï¼Œé¿å…è¶…è¿‡ token é™åˆ¶ï¼‰\n",
        "batch_size = 10\n",
        "\n",
        "enhanced_data = []\n",
        "\n",
        "print(\"å¼€å§‹æ‰¹é‡è°ƒç”¨ OpenRouter API å¤„ç†...\")\n",
        "for i in range(0, len(sentences), batch_size):\n",
        "    batch = sentences[i:i+batch_size]\n",
        "\n",
        "    # ç¼–å·æ˜¾ç¤º\n",
        "    numbered = \"\\n\".join(f\"{j+1}: {sent}\" for j, sent in enumerate(batch))\n",
        "\n",
        "    prompt = prompt_template.format(numbered_sentences=numbered)\n",
        "\n",
        "    print(f\"å¤„ç†ç¬¬ {i+1}-{min(i+batch_size, len(sentences))} å¥ï¼ˆå…± {len(batch)} å¥ï¼‰...\")\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=model_name,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0.3,      # ä½æ¸©åº¦æ›´ç¨³å®š\n",
        "            max_tokens=4096\n",
        "        )\n",
        "\n",
        "        content = response.choices[0].message.content.strip()\n",
        "\n",
        "        # å°è¯•è§£æ JSON\n",
        "        try:\n",
        "            batch_json = json.loads(content)\n",
        "        except json.JSONDecodeError:\n",
        "            print(\"JSON è§£æå¤±è´¥ï¼ŒåŸå§‹è¾“å‡ºï¼š\")\n",
        "            print(content)\n",
        "            print(\"è¯·æ‰‹åŠ¨ä¿®æ­£æˆ–é‡æ–°è¿è¡Œæœ¬æ‰¹\")\n",
        "            continue\n",
        "\n",
        "        enhanced_data.extend(batch_json)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"API è°ƒç”¨å‡ºé”™ï¼š{e}\")\n",
        "        print(\"å¯èƒ½åŸå› ï¼šAPI Key æ— æ•ˆã€é…é¢ä¸è¶³ã€ç½‘ç»œé—®é¢˜\")\n",
        "        break\n",
        "\n",
        "    # ç¤¼è²Œç­‰å¾…ï¼Œé¿å…è§¦å‘é™æµ\n",
        "    time.sleep(2)\n",
        "\n",
        "print(f\"\\nå¤„ç†å®Œæˆï¼å…±å¢å¼º {len(enhanced_data)} æ®µ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-ev4Da4Z5aA"
      },
      "outputs": [],
      "source": [
        "# Cell 5: ä¿å­˜å¢å¼º JSON å¹¶ä¸‹è½½\n",
        "import json\n",
        "from google.colab import files\n",
        "\n",
        "json_filename = os.path.splitext(srt_filename)[0] + \"_enhanced.json\"\n",
        "\n",
        "with open(json_filename, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(enhanced_data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"å¢å¼º JSON å·²ä¿å­˜ä¸ºï¼š{json_filename}\")\n",
        "print(\"\\nå‰ 3 æ¡é¢„è§ˆï¼š\")\n",
        "print(json.dumps(enhanced_data[:3], ensure_ascii=False, indent=2))\n",
        "\n",
        "# è‡ªåŠ¨ä¸‹è½½\n",
        "files.download(json_filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeCVwtIeamhz"
      },
      "source": [
        "## æ­¥éª¤ä¸‰ï¼šè‡ªåŠ¨ç”ŸæˆASSå­—å¹•ï¼ˆå…¨è‡ªåŠ¨ï¼ŒPythonè„šæœ¬ï¼‰"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmYkgZ_9arj9"
      },
      "outputs": [],
      "source": [
        "import pysrt\n",
        "import json\n",
        "import re\n",
        "\n",
        "# åŠ è½½åŸSRTï¼ˆæ—¶é—´è½´ï¼‰\n",
        "subs = pysrt.open(srt_filename)\n",
        "\n",
        "# åŠ è½½AIå¤„ç†çš„JSON\n",
        "with open(json_filename, 'r', encoding='utf-8') as f:\n",
        "    enhanced = json.load(f)\n",
        "\n",
        "# ASSé¢œè‰²å®šä¹‰\n",
        "colors = {\n",
        "    'yellow': '&H00FFFF&',   # ASSé»„è‰²\n",
        "    'orange': '&H00A5FF&',\n",
        "    'red': '&H0000FF&',\n",
        "    'white': '&HFFFFFF&'\n",
        "}\n",
        "\n",
        "def add_color(text):\n",
        "    # æ›¿æ¢[HL:color]ä¸ºASSæ ‡ç­¾\n",
        "    def repl(match):\n",
        "        word = match.group(1)\n",
        "        color = colors.get(match.group(2), colors['white'])\n",
        "        return f'{{\\\\c{color}}}{word}{{\\\\c{colors[\"white\"]}}}'\n",
        "    return re.sub(r'\\[HL:(\\w+?)\\](.*?)\\[/HL\\]', repl, text)\n",
        "\n",
        "# åˆå¹¶\n",
        "for i, sub in enumerate(subs):\n",
        "    item = enhanced[i]\n",
        "    english = add_color(item['english'])\n",
        "    chinese = item['chinese']\n",
        "    annotation = item.get('annotation', '')\n",
        "    # ASSä¸‰è¡Œå¸ƒå±€\n",
        "    sub.text = f\"{english}\\\\N{{\\\\fs20}}{chinese}\\\\N{{\\\\fs18\\\\c&H808080&}}{annotation}\"\n",
        "\n",
        "# ä¿å­˜ASS\n",
        "with open('final.ass', 'w', encoding='utf-8') as f:\n",
        "    f.write('[Script Info]\\nScriptType: v4.00+\\n\\n[V4+ Styles]\\nFormat: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding\\nStyle: Default,Arial,28,&H00FFFFFF,&H000000FF,&H00000000,&H00000000,0,0,0,0,100,100,0,0,1,2,2,2,10,10,30,1\\n\\n[Events]\\nFormat: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text\\n')\n",
        "    for sub in subs:\n",
        "        f.write(f'Dialogue: 0,{sub.start},{sub.end},Default,,0,0,0,,{sub.text}\\n')\n",
        "\n",
        "print(\"ASSå­—å¹•ç”Ÿæˆå®Œæˆï¼\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9jBhDiX8Zds"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ngEr78yNJv0"
      },
      "source": [
        "## ã€è°ƒè¯•ç”¨ï¼Œä¸æ‰§è¡Œã€‘ä¸‹è½½youtubeçš„éŸ³é¢‘è¯•è¯•"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e12ad949"
      },
      "outputs": [],
      "source": [
        "# å®‰è£… yt-dlp\n",
        "!pip install -q yt-dlp\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74bcba22"
      },
      "outputs": [],
      "source": [
        "import yt_dlp\n",
        "import os\n",
        "\n",
        "def download_youtube_audio(youtube_url):\n",
        "    ydl_opts = {\n",
        "        'format': 'bestaudio/best',\n",
        "        'postprocessors': [{\n",
        "            'key': 'FFmpegExtractAudio',\n",
        "            'preferredcodec': 'mp3',\n",
        "            'preferredquality': '192',\n",
        "        }],\n",
        "        'outtmpl': '%(title)s.%(ext)s', # Output filename template\n",
        "        'quiet': True, # Suppress console output for cleaner execution\n",
        "        'no_warnings': True,\n",
        "    }\n",
        "    try:\n",
        "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "            info_dict = ydl.extract_info(youtube_url, download=True)\n",
        "            filename = ydl.prepare_filename(info_dict)\n",
        "            # Change extension to mp3 explicitly\n",
        "            base, ext = os.path.splitext(filename)\n",
        "            mp3_filename = base + '.mp3'\n",
        "            print(f\"æˆåŠŸä¸‹è½½éŸ³é¢‘ï¼š{mp3_filename}\")\n",
        "            return mp3_filename\n",
        "    except Exception as e:\n",
        "        print(f\"ä¸‹è½½å¤±è´¥ï¼š{e}\")\n",
        "        return None\n",
        "\n",
        "# ç¤ºä¾‹ç”¨æ³•ï¼š\n",
        "# youtube_url = 'YOUR_YOUTUBE_URL_HERE'\n",
        "# downloaded_file = download_youtube_audio(youtube_url)\n",
        "# if downloaded_file:\n",
        "#     print(f\"æ–‡ä»¶å·²ä¿å­˜åˆ°ï¼š{downloaded_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ike8-AqNjsV"
      },
      "outputs": [],
      "source": [
        "youtube_url = 'https://www.youtube.com/watch?v=f96t2rsb4Lw'\n",
        "downloaded_file = download_youtube_audio(youtube_url)\n",
        "if downloaded_file:\n",
        "    print(f\"æ–‡ä»¶å·²ä¿å­˜åˆ°ï¼š{downloaded_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9545ed7"
      },
      "source": [
        "ç°åœ¨ä½ å¯ä»¥ä½¿ç”¨ä¸Šé¢çš„ `download_youtube_audio` å‡½æ•°æ¥ä¸‹è½½YouTubeè§†é¢‘çš„éŸ³é¢‘ã€‚åªéœ€å°†ä½ æƒ³è¦ä¸‹è½½çš„YouTubeé“¾æ¥æ›¿æ¢æ‰ `YOUR_YOUTUBE_URL_HERE` å³å¯ã€‚"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqo-nbdY8gSW"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfKaie3f8iFX"
      },
      "source": [
        "## æµ‹è¯•geminiæ¨¡å‹"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IIzdTqHi8nJ2"
      },
      "outputs": [],
      "source": [
        "# å®‰è£… Google å®˜æ–¹æœ€æ–°çš„ GenAI SDK (æ”¯æŒ Gemini 2.0/3.0 ç³»åˆ—)\n",
        "!pip install -q -U google-genai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EbqcGAHz9xhr"
      },
      "outputs": [],
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "from google.colab import userdata\n",
        "import textwrap\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 1. åˆå§‹åŒ–å®¢æˆ·ç«¯\n",
        "# ---------------------------------------------------------\n",
        "# å»ºè®®åœ¨ Colab å·¦ä¾§ \"Secrets\" ä¸­è®¾ç½® GOOGLE_API_KEY\n",
        "try:\n",
        "    API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "except Exception:\n",
        "    API_KEY = \"ä½ çš„_API_KEY_å¡«åœ¨è¿™é‡Œ\"\n",
        "\n",
        "client = genai.Client(api_key=API_KEY)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 2. æ¨¡å‹é…ç½® (é‡ç‚¹ï¼šè®¾ç½®æ€è€ƒèƒ½åŠ›)\n",
        "# ---------------------------------------------------------\n",
        "# Gemini 3 Pro Preview çš„æ ¸å¿ƒç‰¹æ€§æ˜¯å¯æ§çš„æ€è€ƒæ·±åº¦\n",
        "generate_config = types.GenerateContentConfig(\n",
        "    temperature=0.7,\n",
        "    top_p=0.95,\n",
        "    max_output_tokens=8192,\n",
        "\n",
        "    # ã€å…³é”®è®¾ç½®ã€‘å¯ç”¨æ·±åº¦æ€è€ƒæ¨¡å¼\n",
        "    # 'HIGH' é€‚åˆå¤æ‚é€»è¾‘/ç¼–ç¨‹ï¼Œ'LOW' é€‚åˆå¿«é€Ÿå¯¹è¯\n",
        "    # æ³¨æ„ï¼šè¿™æ˜¯ Gemini 3 / 2.0 Flash Thinking ç³»åˆ—ç‰¹æœ‰çš„å‚æ•°ç»“æ„\n",
        "    thinking_config=types.ThinkingConfig(\n",
        "        include_thoughts=True # è®©æ¨¡å‹è¿”å›å®ƒçš„æ€è€ƒè¿‡ç¨‹\n",
        "    )\n",
        ")\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 3. å®šä¹‰æç¤ºè¯\n",
        "# ---------------------------------------------------------\n",
        "prompt = \"\"\"\n",
        "è¯·åˆ†æä¸€ä¸‹ï¼šå¦‚æœäººç±»å®ç°äº†å¯æ§æ ¸èšå˜ï¼Œå¯¹å…¨çƒåœ°ç¼˜æ”¿æ²»æ ¼å±€ä¼šæœ‰å“ªäº›å…·ä½“çš„ã€åˆ†é˜¶æ®µçš„å½±å“ï¼Ÿ\n",
        "è¯·å…ˆè¿›è¡Œæ·±åº¦çš„æ€ç»´é“¾æ¨å¯¼ï¼Œç„¶åå†ç»™å‡ºæœ€ç»ˆç»“è®ºã€‚\n",
        "\"\"\"\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 4. è°ƒç”¨æ¨¡å‹ (ä½¿ç”¨æµå¼ä¼ è¾“ Stream)\n",
        "# ---------------------------------------------------------\n",
        "# è¿™é‡Œçš„æ¨¡å‹ ID æ˜¯æˆ‘ä»¬åœ¨ä¸Šæ–‡ä¸­è®¨è®ºçš„é¢„è§ˆç‰ˆ ID\n",
        "MODEL_ID = \"gemini-3-pro-preview\"\n",
        "\n",
        "# å¦‚æœä½ æ˜¯ 2024/2025 å¹´çš„ç”¨æˆ·ï¼Œè¯·å–æ¶ˆä¸‹é¢è¿™è¡Œçš„æ³¨é‡Šä»¥ä½¿ç”¨å½“æ—¶å¯ç”¨çš„æ¨¡å‹ï¼š\n",
        "# MODEL_ID = \"gemini-2.0-flash-thinking-exp\"\n",
        "\n",
        "print(f\"æ­£åœ¨è°ƒç”¨æ¨¡å‹: {MODEL_ID} ...\\n\")\n",
        "\n",
        "try:\n",
        "    response = client.models.generate_content_stream(\n",
        "        model=MODEL_ID,\n",
        "        contents=prompt,\n",
        "        config=generate_config\n",
        "    )\n",
        "\n",
        "    # ---------------------------------------------------------\n",
        "    # 5. å¤„ç†å¹¶æ˜¾ç¤ºæµå¼è¾“å‡º\n",
        "    # ---------------------------------------------------------\n",
        "    final_text = \"\"\n",
        "    print(\"--- å›ç­”å¼€å§‹ ---\\n\")\n",
        "\n",
        "    for chunk in response:\n",
        "        # æ£€æŸ¥æ˜¯å¦æœ‰æ–‡æœ¬å†…å®¹\n",
        "        if chunk.text:\n",
        "            print(chunk.text, end=\"\", flush=True)\n",
        "            final_text += chunk.text\n",
        "\n",
        "    # å¦‚æœå¼€å¯äº† include_thoughtsï¼Œé€šå¸¸ API ä¼šåœ¨å…ƒæ•°æ®æˆ–ç‰¹å®šå­—æ®µè¿”å›æ€è€ƒè¿‡ç¨‹\n",
        "    # è¿™é‡Œæ¼”ç¤ºç®€å•çš„æ–‡æœ¬æ¥æ”¶\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n\\nè°ƒç”¨å‡ºé”™: {e}\")\n",
        "    print(\"æç¤ºï¼šè¯·æ£€æŸ¥ä½ çš„ API Key æ˜¯å¦æœ‰æƒé™è®¿é—®è¯¥é¢„è§ˆç‰ˆæ¨¡å‹ã€‚\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oANIyxS4qbcb"
      },
      "source": [
        "## å£°éŸ³æå–å­—å¹•"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQ_Wg-AAqgFR"
      },
      "outputs": [],
      "source": [
        "# å®‰è£… openai-whisper\n",
        "!pip install git+https://github.com/openai/whisper.git -q\n",
        "\n",
        "# å®‰è£… ffmpeg (éŸ³é¢‘å¤„ç†å¿…é¡»)\n",
        "!sudo apt update && sudo apt install ffmpeg -q\n",
        "\n",
        "print(\"å®‰è£…å®Œæˆï¼è¯·ç»§ç»­ä¸‹ä¸€æ­¥ã€‚\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        },
        "id": "SEE_XApmrPOZ",
        "outputId": "bd13ef2d-9d0d-4d0b-e890-44320a97ce8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "è¯·ä¸Šä¼ éœ€è¦æå–å­—å¹•çš„éŸ³é¢‘/è§†é¢‘æ–‡ä»¶ï¼š\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-66188757-d0f0-4e61-b7b2-8094ba9c784c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-66188757-d0f0-4e61-b7b2-8094ba9c784c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving veronikaslanguagediaries.mp3 to veronikaslanguagediaries.mp3\n",
            "å·²ä¸Šä¼ æ–‡ä»¶: veronikaslanguagediaries.mp3\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "# æ¸…ç†æ—§æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰\n",
        "!rm -f *.mp3 *.wav *.m4a *.mp4\n",
        "\n",
        "print(\"è¯·ä¸Šä¼ éœ€è¦æå–å­—å¹•çš„éŸ³é¢‘/è§†é¢‘æ–‡ä»¶ï¼š\")\n",
        "uploaded = files.upload()\n",
        "file_name = list(uploaded.keys())[0]\n",
        "\n",
        "print(f\"å·²ä¸Šä¼ æ–‡ä»¶: {file_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POcpNk-JrWQD",
        "outputId": "d0193b35-5bc8-471a-ae2b-7c0746e585a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "æ­£åœ¨æå–å­—å¹•ï¼Œè¯·è€å¿ƒç­‰å¾…ï¼ˆå–å†³äºæ–‡ä»¶æ—¶é•¿ï¼‰...\n",
            "Detected language: English\n",
            "100% 59346/59346 [03:55<00:00, 251.60frames/s]\n",
            "æå–å®Œæˆï¼\n"
          ]
        }
      ],
      "source": [
        "# ä¸ºäº†å¤„ç†æ–‡ä»¶åä¸­çš„ç©ºæ ¼ï¼Œæˆ‘ä»¬å¯¹æ–‡ä»¶ååŠ å¼•å·\n",
        "import shlex\n",
        "\n",
        "safe_filename = shlex.quote(file_name)\n",
        "\n",
        "print(\"æ­£åœ¨æå–å­—å¹•ï¼Œè¯·è€å¿ƒç­‰å¾…ï¼ˆå–å†³äºæ–‡ä»¶æ—¶é•¿ï¼‰...\")\n",
        "# è¿è¡Œ Whisper\n",
        "# å‚æ•°è¯´æ˜ï¼š\n",
        "# --model large-v3 : ä½¿ç”¨æœ€æ–°çš„å¤§æ¨¡å‹ä»¥è·å¾—æœ€é«˜ç²¾åº¦\n",
        "# --output_format srt : ä»…è¾“å‡º srt å­—å¹•æ–‡ä»¶\n",
        "# --verbose False : å‡å°‘è¾“å‡ºæ—¥å¿—ï¼Œåªçœ‹ç»“æœ\n",
        "!whisper {safe_filename} --model large-v3 --output_format srt --verbose False\n",
        "\n",
        "print(\"æå–å®Œæˆï¼\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vkFRxxwvrm6j"
      },
      "outputs": [],
      "source": [
        "# è·å–ç”Ÿæˆçš„ srt æ–‡ä»¶åï¼ˆWhisper ä¼šç”Ÿæˆä¸åŸæ–‡ä»¶ååŒåçš„ .srt æ–‡ä»¶ï¼‰\n",
        "base_name = os.path.splitext(file_name)[0]\n",
        "srt_file = base_name + \".srt\"\n",
        "\n",
        "if os.path.exists(srt_file):\n",
        "    print(f\"æ‰¾åˆ°å­—å¹•æ–‡ä»¶: {srt_file}\\n\")\n",
        "\n",
        "    # æ‰“å°å‰10è¡Œé¢„è§ˆ\n",
        "    print(\"=== å­—å¹•é¢„è§ˆ (å‰10è¡Œ) ===\")\n",
        "    with open(srt_file, 'r', encoding='utf-8') as f:\n",
        "        print(\"\".join(f.readlines()[:10]))\n",
        "    print(\"========================\\n\")\n",
        "\n",
        "    # è‡ªåŠ¨ä¸‹è½½\n",
        "    files.download(srt_file)\n",
        "else:\n",
        "    print(\"æœªæ‰¾åˆ°å­—å¹•æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥ä¸Šä¸€æ­¥æ˜¯å¦æŠ¥é”™ã€‚\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJq73eM-cbP7"
      },
      "source": [
        "## ä½¿ç”¨Qwen3å…‹éš†å£°éŸ³"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZpqibpQch83"
      },
      "outputs": [],
      "source": [
        "# å®‰è£… Qwen-TTS æ ¸å¿ƒåº“åŠç›¸å…³ä¾èµ–\n",
        "!pip install -U qwen-tts transformers accelerate librosa soundfile\n",
        "# ä¸ºäº†æ›´å¿«çš„æ¨ç†é€Ÿåº¦ï¼ˆå¯é€‰ï¼ŒT4 GPU ç¼–è¯‘è¾ƒæ…¢ï¼‰\n",
        "# !pip install flash-attn --no-build-isolation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "mM3cSqmLxVoK",
        "outputId": "501a3b69-156c-46ba-9bba-cd416fe56991"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import soundfile as sf\n",
        "from qwen_tts import Qwen3TTSModel\n",
        "from google.colab import files\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "# 1. æ¨¡å‹é…ç½®\n",
        "# ä¹Ÿå¯ä»¥æ¢æˆ Qwen/Qwen3-TTS-12Hz-1.7B-Instruct (å¦‚æœæœ‰å¯¹è¯ç‰ˆ)\n",
        "model_id = \"Qwen/Qwen3-TTS-12Hz-1.7B-Base\"\n",
        "\n",
        "print(f\"æ­£åœ¨ä» Hugging Face åŠ è½½æ¨¡å‹: {model_id}...\")\n",
        "\n",
        "# 2. åŠ è½½æ¨¡å‹\n",
        "# æç¤ºï¼šT4 GPU æ˜¾å­˜çº¦ä¸º 15GBï¼Œ1.7B æ¨¡å‹åœ¨ bfloat16 ä¸‹çº¦å ç”¨ 4-5GB\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = Qwen3TTSModel.from_pretrained(\n",
        "    model_id,\n",
        "    device_map=device,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    # å¦‚æœæ²¡å®‰è£… flash-attnï¼Œè¯·ä¿æŒä½¿ç”¨ \"sdpa\"\n",
        "    attn_implementation=\"sdpa\"\n",
        ")\n",
        "\n",
        "# 3. ä¸Šä¼ å‚è€ƒéŸ³é¢‘ (Voice Prompt)\n",
        "print(\"\\n--- è¯·ä¸Šä¼ å‚è€ƒéŸ³é¢‘æ–‡ä»¶ (å»ºè®® 3-10 ç§’ï¼ŒWAV/MP3) ---\")\n",
        "uploaded = files.upload()\n",
        "if not uploaded:\n",
        "    raise ValueError(\"æœªä¸Šä¼ ä»»ä½•æ–‡ä»¶ï¼Œè¯·é‡æ–°è¿è¡Œæ­¤å•å…ƒæ ¼ã€‚\")\n",
        "\n",
        "ref_audio_path = list(uploaded.keys())[0]\n",
        "\n",
        "# 4. è®¾ç½®å‚æ•°\n",
        "# æ³¨æ„ï¼šæä¾›å‚è€ƒéŸ³é¢‘ä¸­çš„å‡†ç¡®æ–‡æœ¬æœ‰åŠ©äºæ¨¡å‹æ›´å¥½åœ°æ•æ‰éŸ³è‰²\n",
        "ref_text = input(\"è¯·è¾“å…¥å‚è€ƒéŸ³é¢‘ä¸­æ­£åœ¨è¯´çš„å†…å®¹ï¼ˆæ”¯æŒä¸­/è‹±/æ—¥ç­‰ï¼‰: \")\n",
        "target_text = input(\"è¯·è¾“å…¥ä½ æƒ³è¦åˆæˆçš„ç›®æ ‡æ–‡æœ¬: \")\n",
        "\n",
        "print(\"\\n--- æ­£åœ¨æ‰§è¡Œå£°éŸ³å…‹éš† ---\")\n",
        "\n",
        "# 5. æ‰§è¡Œæ¨ç†\n",
        "# ç¬¬ä¸€æ­¥ï¼šæå–éŸ³é¢‘ç‰¹å¾ä½œä¸º Prompt\n",
        "voice_clone_prompt = model.create_voice_clone_prompt(\n",
        "    ref_audio=ref_audio_path,\n",
        "    ref_text=ref_text\n",
        ")\n",
        "\n",
        "# ç¬¬äºŒæ­¥ï¼šæ ¹æ® Prompt ç”Ÿæˆç›®æ ‡è¯­éŸ³\n",
        "# è¯¥æ¨¡å‹æ”¯æŒä¸­ã€è‹±ã€æ—¥ã€éŸ©ã€å¾·ã€æ³•ã€æ„ã€ä¿„ã€è¥¿ã€è‘¡\n",
        "wavs, sr = model.generate_voice_clone(\n",
        "    text=target_text,\n",
        "    language=\"english\", # è¿™é‡Œå¯ä»¥æ ¹æ®éœ€è¦ä¿®æ”¹ç›®æ ‡è¯­è¨€\n",
        "    voice_clone_prompt=voice_clone_prompt\n",
        ")\n",
        "\n",
        "# 6. ä¿å­˜å¹¶æ’­æ”¾ç»“æœ\n",
        "output_filename = \"huggingface_output.wav\"\n",
        "sf.write(output_filename, wavs[0], sr)\n",
        "\n",
        "print(f\"\\nç”ŸæˆæˆåŠŸï¼å·²ä¿å­˜ä¸º: {output_filename}\")\n",
        "display(Audio(output_filename, autoplay=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ä½¿ç”¨Qwen3è®¾è®¡å£°éŸ³å†ç”ŸæˆéŸ³é¢‘"
      ],
      "metadata": {
        "id": "5y9hElNvbCr5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U qwen-tts transformers accelerate soundfile"
      ],
      "metadata": {
        "id": "jQiD0tK7bYUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import soundfile as sf\n",
        "from qwen_tts import Qwen3TTSModel\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "# 1. åŠ è½½æ¨¡å‹\n",
        "model_id = \"Qwen/Qwen3-TTS-12Hz-1.7B-Base\"\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "print(f\"æ­£åœ¨åŠ è½½ Qwen3-TTS æ¨¡å‹...\")\n",
        "model = Qwen3TTSModel.from_pretrained(\n",
        "    model_id,\n",
        "    device_map=device,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    attn_implementation=\"sdpa\" # Colab T4 å»ºè®®ä½¿ç”¨ sdpa\n",
        ")\n",
        "\n",
        "# 2. è¯­éŸ³è®¾è®¡ (Voice Design)\n",
        "# è¿™æ˜¯å…³é”®æ­¥éª¤ï¼šé€šè¿‡æ–‡å­—æè¿°å®šä¹‰éŸ³è‰²\n",
        "print(\"\\n--- æ­£åœ¨é€šè¿‡æè¿°è®¾è®¡è€è€…éŸ³è‰² ---\")\n",
        "\n",
        "# æè¿°è¯å»ºè®®ä½¿ç”¨è‹±æ–‡ä»¥è·å¾—æ›´ç²¾ç¡®çš„ç†è§£\n",
        "# æè¿°åŒ…å«ï¼šæ€§åˆ«ã€å¹´é¾„ã€éŸ³è°ƒã€è¯­é€Ÿã€æ€§æ ¼ç‰¹ç‚¹\n",
        "voice_description = (\n",
        "    \"A deep-voiced elderly American man. \"\n",
        "    \"His voice is low-pitched, slightly gravelly, sounding very wise and calm. \"\n",
        "    \"He speaks at a very slow and deliberate pace, with clear pauses.\"\n",
        ")\n",
        "\n",
        "# ç»™è®¾è®¡å¥½çš„å£°éŸ³ä¸€æ®µâ€œåˆå§‹æ–‡æœ¬â€ä½œä¸ºå‚è€ƒ\n",
        "design_ref_text = \"Knowledge is proud that he has learned so much; Wisdom is humble that he knows no more.\"\n",
        "\n",
        "# ç”Ÿæˆè™šæ‹Ÿçš„éŸ³è‰² Prompt\n",
        "voice_design_prompt = model.generate_voice_design(\n",
        "    description=voice_description,\n",
        "    ref_text=design_ref_text\n",
        ")\n",
        "\n",
        "# 3. è®¾ç½®è¦æœ—è¯»çš„å“²ç†æ–‡ç« \n",
        "# æˆ‘ä»¬å¢åŠ äº†ä¸€äº›æ ‡ç‚¹ç¬¦å·ï¼ˆå¦‚ ...ï¼‰æ¥å¼•å¯¼æ¨¡å‹åœé¡¿æ›´ä¹…\n",
        "philosophical_article = \"\"\"\n",
        "The Starfish Story.\n",
        "An old man was walking on the beach after a storm...\n",
        "He saw a young boy picking up starfish and throwing them back into the ocean.\n",
        "The old man asked: Why are you doing this? You cannot save them all. It does not matter.\n",
        "The boy picked up one more starfish... and threw it into the water.\n",
        "He smiled and said: It matters... to this one.\n",
        "\"\"\"\n",
        "\n",
        "# 4. æ‰§è¡Œå…‹éš†åˆæˆ (Voice Clone)\n",
        "print(\"æ­£åœ¨ä½¿ç”¨è®¾è®¡çš„éŸ³è‰²ç”Ÿæˆè¯­éŸ³...\")\n",
        "wavs, sr = model.generate_voice_clone(\n",
        "    text=philosophical_article,\n",
        "    language=\"English\",\n",
        "    voice_clone_prompt=voice_design_prompt\n",
        ")\n",
        "\n",
        "# 5. ä¿å­˜å¹¶å±•ç¤º\n",
        "output_path = \"designed_old_man_voice.wav\"\n",
        "sf.write(output_path, wavs[0], sr)\n",
        "\n",
        "print(f\"\\nç”ŸæˆæˆåŠŸï¼å·²ä¿å­˜ä¸º: {output_path}\")\n",
        "display(Audio(output_path, autoplay=True))"
      ],
      "metadata": {
        "id": "K18vDJ2pbmNZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyMEJiV7lyEIlpqDk4+A1XDV",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}