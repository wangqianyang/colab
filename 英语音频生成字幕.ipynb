{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1abOtBYPZ4mr_FxspSAu23cn6TgTwcY-b",
      "authorship_tag": "ABX9TyMs8xtPzh03gIAzdJs+dRZD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wangqianyang/colab/blob/main/%E8%8B%B1%E8%AF%AD%E9%9F%B3%E9%A2%91%E7%94%9F%E6%88%90%E5%AD%97%E5%B9%95.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## æ­¥éª¤ä¸€ï¼šç”ŸæˆSRTå­—å¹•"
      ],
      "metadata": {
        "id": "d41k-vn4eGx0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78eJ1c3GIQU3"
      },
      "outputs": [],
      "source": [
        "# å®‰è£… faster-whisperï¼ˆæ›´å¿«ã€æ›´çœæ˜¾å­˜ï¼‰å’Œ ffmpeg\n",
        "!pip install -q faster-whisper\n",
        "!apt-get install -y ffmpeg -qq"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ä¸Šä¼ æ–‡ä»¶"
      ],
      "metadata": {
        "id": "Sbb-hZT-IgSm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# ä¸Šä¼ ä½ çš„éŸ³é¢‘æ–‡ä»¶ï¼ˆæ”¯æŒ mp3, wav, m4a, mp4 ç­‰å¸¸è§æ ¼å¼ï¼‰\n",
        "uploaded = files.upload()\n",
        "\n",
        "# è·å–ä¸Šä¼ çš„æ–‡ä»¶åï¼ˆå‡è®¾åªä¸Šä¼ ä¸€ä¸ªéŸ³é¢‘æ–‡ä»¶ï¼‰\n",
        "audio_file = list(uploaded.keys())[0]\n",
        "print(f\"å·²ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶ï¼š{audio_file}\")"
      ],
      "metadata": {
        "id": "RxWzLnWuIjl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### åŠ è½½æ¨¡å‹å¹¶è½¬å½•ï¼Œç”Ÿæˆ SRT å­—å¹•"
      ],
      "metadata": {
        "id": "V7fBLpBjIyx_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from faster_whisper import WhisperModel\n",
        "import datetime\n",
        "import os\n",
        "\n",
        "# æ¨¡å‹è®¾ç½®ï¼ˆå¦‚æœ large-v3 æ˜¾å­˜ä¸å¤Ÿï¼Œæ”¹æˆ \"medium\"ï¼‰\n",
        "model_size = \"large-v3\"  # è¯•è¯• \"medium\" æˆ– \"small\" å¦‚æœæŠ¥é”™\n",
        "\n",
        "model = WhisperModel(model_size, device=\"cuda\", compute_type=\"float16\")\n",
        "\n",
        "# å…³é”®ä¿®æ”¹ï¼šå…³é—­ VAD è¿‡æ»¤ + è‡ªåŠ¨æ£€æµ‹è¯­è¨€ + é™ä½é˜ˆå€¼\n",
        "segments_iterator, info = model.transcribe(\n",
        "    audio_file,\n",
        "    language=None,          # è‡ªåŠ¨æ£€æµ‹è¯­è¨€ï¼ˆå¾ˆé‡è¦ï¼ï¼‰\n",
        "    beam_size=5,\n",
        "    vad_filter=False,       # å…ˆå…³é—­ VADï¼Œé¿å…è¿‡åº¦è¿‡æ»¤\n",
        "    vad_parameters=dict(min_silence_duration_ms=500),  # å³ä½¿å¼€ VAD ä¹Ÿæ”¾å®½\n",
        "    word_timestamps=True,\n",
        "    temperature=0.0,        # æ›´ç¡®å®šæ€§è¾“å‡º\n",
        "    no_speech_threshold=0.6,  # é»˜è®¤ 0.6ï¼Œè°ƒä½åˆ° 0.4 å¯ä»¥æ›´æ•æ„Ÿï¼ˆå¦‚æœä»ç©ºå†è¯•ï¼‰\n",
        ")\n",
        "\n",
        "# å°† segments è¿­ä»£å™¨è½¬æ¢ä¸ºåˆ—è¡¨ï¼Œä»¥ä¾¿å¤šæ¬¡ä½¿ç”¨\n",
        "segments = list(segments_iterator)\n",
        "\n",
        "# === è¯Šæ–­ä¿¡æ¯è¾“å‡º ===\n",
        "print(f\"æ£€æµ‹åˆ°è¯­è¨€: {info.language} (æ¦‚ç‡: {info.language_probability:.2f})\")\n",
        "print(f\"è½¬å½•æ—¶é•¿: {info.duration:.2f} ç§’\")\n",
        "print(f\"æ£€æµ‹åˆ°æ®µè½æ•°é‡: {len(segments)}\") # ä½¿ç”¨å·²è½¬æ¢ä¸ºåˆ—è¡¨çš„ segments\n",
        "\n",
        "if info.language_probability < 0.5:\n",
        "    print(\"è­¦å‘Šï¼šè¯­è¨€æ£€æµ‹ç½®ä¿¡åº¦ä½ï¼Œå¯èƒ½æ˜¯éè¯­éŸ³å†…å®¹æˆ–å™ªéŸ³ã€‚\")\n",
        "\n",
        "if len(segments) == 0: # ä½¿ç”¨å·²è½¬æ¢ä¸ºåˆ—è¡¨çš„ segments\n",
        "    print(\"é”™è¯¯ï¼šæ²¡æœ‰æ£€æµ‹åˆ°ä»»ä½•è¯­éŸ³æ®µè½ï¼å¯èƒ½åŸå› ï¼š\")\n",
        "    print(\"  - éŸ³é¢‘æ— å£°æˆ–åªæœ‰èƒŒæ™¯éŸ³ä¹\")\n",
        "    print(\"  - æ–‡ä»¶æŸå\")\n",
        "    print(\"  - éœ€è¦æ›´ä½çš„ no_speech_thresholdï¼ˆè¯•è¯• 0.4ï¼‰\")\n",
        "    print(\"  - å°è¯•å…³é—­ vad_filter æˆ–æ¢å°æ¨¡å‹\")\n",
        "else:\n",
        "    print(\"æˆåŠŸæ£€æµ‹åˆ°è¯­éŸ³ï¼\")\n",
        "\n",
        "# å¦‚æœæœ‰æ®µè½ï¼Œæ‰ç”Ÿæˆ SRT\n",
        "if len(segments) > 0: # ä½¿ç”¨å·²è½¬æ¢ä¸ºåˆ—è¡¨çš„ segments\n",
        "    def format_timestamp(seconds: float):\n",
        "        td = datetime.timedelta(seconds=seconds)\n",
        "        hours, remainder = divmod(td.total_seconds(), 3600)\n",
        "        minutes, seconds = divmod(remainder, 60)\n",
        "        milliseconds = int((seconds - int(seconds)) * 1000)\n",
        "        return f\"{int(hours):02}:{int(minutes):02}:{int(seconds):02},{milliseconds:03}\"\n",
        "\n",
        "    srt_content = \"\"\n",
        "    for i, segment in enumerate(segments, start=1): # ä½¿ç”¨å·²è½¬æ¢ä¸ºåˆ—è¡¨çš„ segments\n",
        "        start_time = format_timestamp(segment.start)\n",
        "        end_time = format_timestamp(segment.end)\n",
        "        text = segment.text.strip()\n",
        "        srt_content += f\"{i}\\n{start_time} --> {end_time}\\n{text}\\n\\n\"\n",
        "\n",
        "    srt_filename = os.path.splitext(audio_file)[0] + \".srt\"\n",
        "    with open(srt_filename, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(srt_content)\n",
        "\n",
        "    print(f\"SRT å­—å¹•å·²ä¿å­˜ä¸ºï¼š{srt_filename}\")\n",
        "    files.download(srt_filename)\n",
        "else:\n",
        "    print(\"ç”±äºæ²¡æœ‰æ£€æµ‹åˆ°è¯­éŸ³ï¼ŒSRT æ–‡ä»¶æœªç”Ÿæˆã€‚\")\n",
        "\n",
        "# å§‹ç»ˆé¢„è§ˆè¯Šæ–­ï¼ˆå³ä½¿ä¸ºç©ºï¼‰\n",
        "print(\"\\n=== é¢å¤–è°ƒè¯•ï¼šå°è¯•æ‰“å°åŸå§‹ info ===\")\n",
        "print(info)\n"
      ],
      "metadata": {
        "id": "cNEb7t9aI1Fa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ï¼ˆå¯é€‰ï¼‰ï¼šé¢„è§ˆå‰å‡ è¡Œå­—å¹•"
      ],
      "metadata": {
        "id": "HMfGgW7_JpKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# æ‰“å°å‰ 10 æ®µå­—å¹•é¢„è§ˆ\n",
        "print(\"\\n=== å‰ 10 æ®µå­—å¹•é¢„è§ˆ ===\\n\")\n",
        "preview_segments = list(segments)[:10]\n",
        "for i, segment in enumerate(preview_segments, start=1):\n",
        "    print(f\"{i}\\n{format_timestamp(segment.start)} --> {format_timestamp(segment.end)}\\n{segment.text.strip()}\\n\")"
      ],
      "metadata": {
        "id": "PKmgrdk0Jq3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## æ­¥éª¤äºŒï¼šAIè¯†åˆ«é‡ç‚¹å¹¶ç”ŸæˆåŒè¯­+æ³¨è§£"
      ],
      "metadata": {
        "id": "xOkPcAhxRyKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: å®‰è£…å¿…è¦åº“ï¼ˆåªéœ€è¿è¡Œä¸€æ¬¡ï¼‰\n",
        "!pip install -q openai pysrt"
      ],
      "metadata": {
        "id": "JNLHDJuDR5jV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: ä¸Šä¼ æˆ–åŠ è½½ä½ çš„ SRT æ–‡ä»¶ï¼ˆå¦‚æœå·²ç»ä¸Šä¼ è¿‡ï¼Œå¯è·³è¿‡ä¸Šä¼ ç›´æ¥æŒ‡å®šæ–‡ä»¶åï¼‰\n",
        "from google.colab import files\n",
        "import pysrt\n",
        "import os\n",
        "\n",
        "# å¦‚æœä½ å·²ç»è¿è¡Œè¿‡ç¬¬ä¸€æ­¥ï¼ŒSRT æ–‡ä»¶åº”è¯¥å·²ç»åœ¨ Colab ç¯å¢ƒä¸­\n",
        "# ç›´æ¥æŒ‡å®šæ–‡ä»¶åï¼ˆæ›¿æ¢æˆä½ çš„å®é™… SRT æ–‡ä»¶åï¼Œä¾‹å¦‚ \"your_audio.srt\"ï¼‰\n",
        "srt_filename = \"001.srt\"  # <--- è¿™é‡Œæ”¹æˆä½ çš„ SRT æ–‡ä»¶å !!!\n",
        "\n",
        "# å¦‚æœæ–‡ä»¶ä¸åœ¨ï¼Œç›´æ¥ä¸Šä¼ \n",
        "if not os.path.exists(srt_filename):\n",
        "    print(\"æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·ä¸Šä¼  SRT æ–‡ä»¶\")\n",
        "    uploaded = files.upload()\n",
        "    srt_filename = list(uploaded.keys())[0]\n",
        "\n",
        "# åŠ è½½ SRT å¹¶æå–çº¯æ–‡æœ¬å¥å­ï¼ˆæŒ‰æ®µè½é¡ºåºï¼‰\n",
        "subs = pysrt.open(srt_filename, encoding='utf-8')\n",
        "\n",
        "# æå–æ¯æ®µçš„çº¯æ–‡æœ¬ï¼ˆå»æ‰æ—¶é—´æˆ³ï¼Œåªä¿ç•™æ–‡å­—ï¼‰\n",
        "sentences = [sub.text.strip().replace('\\n', ' ') for sub in subs if sub.text.strip()]\n",
        "\n",
        "print(f\"æˆåŠŸåŠ è½½ SRTï¼Œå…± {len(sentences)} æ®µå¥å­\")\n",
        "print(\"\\nå‰ 10 å¥é¢„è§ˆï¼š\")\n",
        "for i, sent in enumerate(sentences[:10], 1):\n",
        "    print(f\"{i}: {sent}\")"
      ],
      "metadata": {
        "id": "vWCjT8QVSEuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4410dacf"
      },
      "source": [
        "### ä½¿ç”¨ OpenRouter GPT-OSS æ¨¡å‹ è¯†åˆ«é‡ç‚¹å•è¯å’Œè¯ç»„\n",
        "\n",
        "#### 1. è®¾ç½® OpenRouter API Key\n",
        "\n",
        "æ‚¨éœ€è¦ä¸€ä¸ª OpenRouter API å¯†é’¥ã€‚å¦‚æœè¿˜æ²¡æœ‰ï¼Œè¯·å‰å¾€ [https://openrouter.ai/keys](https://openrouter.ai/keys) åˆ›å»ºä¸€ä¸ªã€‚\n",
        "åœ¨ Colab ä¸­ï¼Œé€šè¿‡å·¦ä¾§é¢æ¿çš„â€œğŸ”‘â€å›¾æ ‡å°†å¯†é’¥æ·»åŠ åˆ° Secrets Managerã€‚å°†å…¶å‘½åä¸º `OPENROUTER_API_KEY`ã€‚ç„¶åä»£ç å°†è‡ªåŠ¨è·å–è¯¥å¯†é’¥ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2398e14c"
      },
      "source": [
        "import getpass\n",
        "from google.colab import userdata\n",
        "\n",
        "# è·å– Colab Secrets ä¸­ä¿å­˜çš„ OPENROUTER_API_KEY\n",
        "OPENROUTER_API_KEY = userdata.get('OPENROUTER_API_KEY')\n",
        "\n",
        "if not OPENROUTER_API_KEY:\n",
        "    print(\"è­¦å‘Šï¼šæœªæ‰¾åˆ° OPENROUTER_API_KEYã€‚è¯·ç¡®ä¿æ‚¨å·²åœ¨ Colab Secrets ä¸­è®¾ç½®å®ƒã€‚\")\n",
        "else:\n",
        "    print(\"OpenRouter API Key å·²è®¾ç½®\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ec4a11db"
      },
      "source": [
        "# Cell 4: å®šä¹‰ Prompt æ¨¡æ¿ + æ‰¹é‡è°ƒç”¨ OpenRouter API\n",
        "import json\n",
        "import time\n",
        "from openai import OpenAI # OpenRouter å…¼å®¹ OpenAI API\n",
        "\n",
        "# ä½¿ç”¨ OpenAI å…¼å®¹æ ¼å¼è°ƒç”¨ OpenRouter API\n",
        "client = OpenAI(\n",
        "    api_key=OPENROUTER_API_KEY,\n",
        "    base_url=\"https://openrouter.ai/api/v1\"\n",
        ")\n",
        "\n",
        "# OpenRouter æ¨¡å‹åç§°\n",
        "model_name = \"openai/gpt-oss-120b:free\"\n",
        "\n",
        "# Prompt æ¨¡æ¿ï¼ˆä¸¥æ ¼å‚è€ƒ BBC / EnglishClass101 é£æ ¼ï¼‰\n",
        "prompt_template = \"\"\"\n",
        "ä½ æ˜¯è‹±è¯­å­¦ä¹ å­—å¹•ä¸“å®¶ï¼Œå‚è€ƒBBC Learning Englishã€English Addict with Mr Steveå’ŒEnglishClass101çš„å­—å¹•é£æ ¼ã€‚\n",
        "ä¸ºæ¯å¥è‹±æ–‡è¾“å‡ºï¼š\n",
        "1. è‹±æ–‡åŸæ–‡ï¼šé‡ç‚¹å•è¯/çŸ­è¯­ç”¨[HL:yellow]æ ‡è®°ï¼ˆç”Ÿè¯/é«˜é¢‘æ–°è¯ï¼‰ï¼Œä¹ è¯­/æ­é…ç”¨[HL:red]æ ‡è®°ã€‚\n",
        "2. ä¸­æ–‡ç¿»è¯‘ï¼šè‡ªç„¶æµç•…ã€é€‚åˆå­¦ä¹ è€…ã€‚\n",
        "3. æ³¨è§£è¡Œï¼ˆå¯é€‰ï¼‰ï¼šä»…å¯¹é‡ç‚¹è¯æ·»åŠ ç®€çŸ­æ‹¬å·è§£é‡Šï¼Œå¦‚ (run into = å¶é‡ï¼Œmeet by chance)ã€‚æ³¨è§£è¦æç®€ï¼Œåªå‡ºç°å¿…è¦æ—¶ã€‚\n",
        "\n",
        "è¾“å‡ºä¸¥æ ¼ä¸º JSON æ•°ç»„ï¼ˆæ— éœ€å…¶ä»–æ–‡å­—ï¼‰ï¼Œæ¯ä¸ªå¯¹è±¡å¯¹åº”ä¸€å¥ï¼š\n",
        "[\n",
        "  {{\n",
        "    \"english\": \"æ ‡è®°åçš„è‹±æ–‡\",\n",
        "    \"chinese\": \"ä¸­æ–‡ç¿»è¯‘\",\n",
        "    \"annotation\": \"æ³¨è§£ï¼ˆå¦‚æœæ²¡æœ‰åˆ™ä¸ºç©ºå­—ç¬¦ä¸² \"\"ï¼‰\"\n",
        "  }},\n",
        "  ...\n",
        "]\n",
        "\n",
        "ç°åœ¨å¤„ç†ä»¥ä¸‹å¥å­ï¼ˆæ¯å¥ç”¨æ•°å­—ç¼–å·ï¼‰ï¼š\n",
        "{numbered_sentences}\n",
        "\n",
        "åªè¾“å‡º JSONï¼\n",
        "\"\"\"\n",
        "\n",
        "# æ‰¹é‡å¤§å°ï¼ˆå»ºè®® 8-12 å¥ä¸€æ‰¹ï¼Œé¿å…è¶…è¿‡ token é™åˆ¶ï¼‰\n",
        "batch_size = 10\n",
        "\n",
        "enhanced_data = []\n",
        "\n",
        "print(\"å¼€å§‹æ‰¹é‡è°ƒç”¨ OpenRouter API å¤„ç†...\")\n",
        "for i in range(0, len(sentences), batch_size):\n",
        "    batch = sentences[i:i+batch_size]\n",
        "\n",
        "    # ç¼–å·æ˜¾ç¤º\n",
        "    numbered = \"\\n\".join(f\"{j+1}: {sent}\" for j, sent in enumerate(batch))\n",
        "\n",
        "    prompt = prompt_template.format(numbered_sentences=numbered)\n",
        "\n",
        "    print(f\"å¤„ç†ç¬¬ {i+1}-{min(i+batch_size, len(sentences))} å¥ï¼ˆå…± {len(batch)} å¥ï¼‰...\")\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=model_name,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0.3,      # ä½æ¸©åº¦æ›´ç¨³å®š\n",
        "            max_tokens=4096\n",
        "        )\n",
        "\n",
        "        content = response.choices[0].message.content.strip()\n",
        "\n",
        "        # å°è¯•è§£æ JSON\n",
        "        try:\n",
        "            batch_json = json.loads(content)\n",
        "        except json.JSONDecodeError:\n",
        "            print(\"JSON è§£æå¤±è´¥ï¼ŒåŸå§‹è¾“å‡ºï¼š\")\n",
        "            print(content)\n",
        "            print(\"è¯·æ‰‹åŠ¨ä¿®æ­£æˆ–é‡æ–°è¿è¡Œæœ¬æ‰¹\")\n",
        "            continue\n",
        "\n",
        "        enhanced_data.extend(batch_json)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"API è°ƒç”¨å‡ºé”™ï¼š{e}\")\n",
        "        print(\"å¯èƒ½åŸå› ï¼šAPI Key æ— æ•ˆã€é…é¢ä¸è¶³ã€ç½‘ç»œé—®é¢˜\")\n",
        "        break\n",
        "\n",
        "    # ç¤¼è²Œç­‰å¾…ï¼Œé¿å…è§¦å‘é™æµ\n",
        "    time.sleep(2)\n",
        "\n",
        "print(f\"\\nå¤„ç†å®Œæˆï¼å…±å¢å¼º {len(enhanced_data)} æ®µ\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: ä¿å­˜å¢å¼º JSON å¹¶ä¸‹è½½\n",
        "import json\n",
        "from google.colab import files\n",
        "\n",
        "json_filename = os.path.splitext(srt_filename)[0] + \"_enhanced.json\"\n",
        "\n",
        "with open(json_filename, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(enhanced_data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"å¢å¼º JSON å·²ä¿å­˜ä¸ºï¼š{json_filename}\")\n",
        "print(\"\\nå‰ 3 æ¡é¢„è§ˆï¼š\")\n",
        "print(json.dumps(enhanced_data[:3], ensure_ascii=False, indent=2))\n",
        "\n",
        "# è‡ªåŠ¨ä¸‹è½½\n",
        "files.download(json_filename)"
      ],
      "metadata": {
        "id": "j-ev4Da4Z5aA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## æ­¥éª¤ä¸‰ï¼šè‡ªåŠ¨ç”ŸæˆASSå­—å¹•ï¼ˆå…¨è‡ªåŠ¨ï¼ŒPythonè„šæœ¬ï¼‰"
      ],
      "metadata": {
        "id": "KeCVwtIeamhz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pysrt\n",
        "import json\n",
        "import re\n",
        "\n",
        "# åŠ è½½åŸSRTï¼ˆæ—¶é—´è½´ï¼‰\n",
        "subs = pysrt.open(srt_filename)\n",
        "\n",
        "# åŠ è½½AIå¤„ç†çš„JSON\n",
        "with open(json_filename, 'r', encoding='utf-8') as f:\n",
        "    enhanced = json.load(f)\n",
        "\n",
        "# ASSé¢œè‰²å®šä¹‰\n",
        "colors = {\n",
        "    'yellow': '&H00FFFF&',   # ASSé»„è‰²\n",
        "    'orange': '&H00A5FF&',\n",
        "    'red': '&H0000FF&',\n",
        "    'white': '&HFFFFFF&'\n",
        "}\n",
        "\n",
        "def add_color(text):\n",
        "    # æ›¿æ¢[HL:color]ä¸ºASSæ ‡ç­¾\n",
        "    def repl(match):\n",
        "        word = match.group(1)\n",
        "        color = colors.get(match.group(2), colors['white'])\n",
        "        return f'{{\\\\c{color}}}{word}{{\\\\c{colors[\"white\"]}}}'\n",
        "    return re.sub(r'\\[HL:(\\w+?)\\](.*?)\\[/HL\\]', repl, text)\n",
        "\n",
        "# åˆå¹¶\n",
        "for i, sub in enumerate(subs):\n",
        "    item = enhanced[i]\n",
        "    english = add_color(item['english'])\n",
        "    chinese = item['chinese']\n",
        "    annotation = item.get('annotation', '')\n",
        "    # ASSä¸‰è¡Œå¸ƒå±€\n",
        "    sub.text = f\"{english}\\\\N{{\\\\fs20}}{chinese}\\\\N{{\\\\fs18\\\\c&H808080&}}{annotation}\"\n",
        "\n",
        "# ä¿å­˜ASS\n",
        "with open('final.ass', 'w', encoding='utf-8') as f:\n",
        "    f.write('[Script Info]\\nScriptType: v4.00+\\n\\n[V4+ Styles]\\nFormat: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding\\nStyle: Default,Arial,28,&H00FFFFFF,&H000000FF,&H00000000,&H00000000,0,0,0,0,100,100,0,0,1,2,2,2,10,10,30,1\\n\\n[Events]\\nFormat: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text\\n')\n",
        "    for sub in subs:\n",
        "        f.write(f'Dialogue: 0,{sub.start},{sub.end},Default,,0,0,0,,{sub.text}\\n')\n",
        "\n",
        "print(\"ASSå­—å¹•ç”Ÿæˆå®Œæˆï¼\")"
      ],
      "metadata": {
        "id": "rmYkgZ_9arj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t9jBhDiX8Zds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ã€è°ƒè¯•ç”¨ï¼Œä¸æ‰§è¡Œã€‘ä¸‹è½½youtubeçš„éŸ³é¢‘è¯•è¯•"
      ],
      "metadata": {
        "id": "8ngEr78yNJv0"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e12ad949"
      },
      "source": [
        "# å®‰è£… yt-dlp\n",
        "!pip install -q yt-dlp\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74bcba22"
      },
      "source": [
        "import yt_dlp\n",
        "import os\n",
        "\n",
        "def download_youtube_audio(youtube_url):\n",
        "    ydl_opts = {\n",
        "        'format': 'bestaudio/best',\n",
        "        'postprocessors': [{\n",
        "            'key': 'FFmpegExtractAudio',\n",
        "            'preferredcodec': 'mp3',\n",
        "            'preferredquality': '192',\n",
        "        }],\n",
        "        'outtmpl': '%(title)s.%(ext)s', # Output filename template\n",
        "        'quiet': True, # Suppress console output for cleaner execution\n",
        "        'no_warnings': True,\n",
        "    }\n",
        "    try:\n",
        "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "            info_dict = ydl.extract_info(youtube_url, download=True)\n",
        "            filename = ydl.prepare_filename(info_dict)\n",
        "            # Change extension to mp3 explicitly\n",
        "            base, ext = os.path.splitext(filename)\n",
        "            mp3_filename = base + '.mp3'\n",
        "            print(f\"æˆåŠŸä¸‹è½½éŸ³é¢‘ï¼š{mp3_filename}\")\n",
        "            return mp3_filename\n",
        "    except Exception as e:\n",
        "        print(f\"ä¸‹è½½å¤±è´¥ï¼š{e}\")\n",
        "        return None\n",
        "\n",
        "# ç¤ºä¾‹ç”¨æ³•ï¼š\n",
        "# youtube_url = 'YOUR_YOUTUBE_URL_HERE'\n",
        "# downloaded_file = download_youtube_audio(youtube_url)\n",
        "# if downloaded_file:\n",
        "#     print(f\"æ–‡ä»¶å·²ä¿å­˜åˆ°ï¼š{downloaded_file}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "youtube_url = 'https://www.youtube.com/watch?v=f96t2rsb4Lw'\n",
        "downloaded_file = download_youtube_audio(youtube_url)\n",
        "if downloaded_file:\n",
        "    print(f\"æ–‡ä»¶å·²ä¿å­˜åˆ°ï¼š{downloaded_file}\")"
      ],
      "metadata": {
        "id": "7ike8-AqNjsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9545ed7"
      },
      "source": [
        "ç°åœ¨ä½ å¯ä»¥ä½¿ç”¨ä¸Šé¢çš„ `download_youtube_audio` å‡½æ•°æ¥ä¸‹è½½YouTubeè§†é¢‘çš„éŸ³é¢‘ã€‚åªéœ€å°†ä½ æƒ³è¦ä¸‹è½½çš„YouTubeé“¾æ¥æ›¿æ¢æ‰ `YOUR_YOUTUBE_URL_HERE` å³å¯ã€‚"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qqo-nbdY8gSW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## æµ‹è¯•geminiæ¨¡å‹"
      ],
      "metadata": {
        "id": "FfKaie3f8iFX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# å®‰è£… Google å®˜æ–¹æœ€æ–°çš„ GenAI SDK (æ”¯æŒ Gemini 2.0/3.0 ç³»åˆ—)\n",
        "!pip install -q -U google-genai"
      ],
      "metadata": {
        "id": "IIzdTqHi8nJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "from google.colab import userdata\n",
        "import textwrap\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 1. åˆå§‹åŒ–å®¢æˆ·ç«¯\n",
        "# ---------------------------------------------------------\n",
        "# å»ºè®®åœ¨ Colab å·¦ä¾§ \"Secrets\" ä¸­è®¾ç½® GOOGLE_API_KEY\n",
        "try:\n",
        "    API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "except Exception:\n",
        "    API_KEY = \"ä½ çš„_API_KEY_å¡«åœ¨è¿™é‡Œ\"\n",
        "\n",
        "client = genai.Client(api_key=API_KEY)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 2. æ¨¡å‹é…ç½® (é‡ç‚¹ï¼šè®¾ç½®æ€è€ƒèƒ½åŠ›)\n",
        "# ---------------------------------------------------------\n",
        "# Gemini 3 Pro Preview çš„æ ¸å¿ƒç‰¹æ€§æ˜¯å¯æ§çš„æ€è€ƒæ·±åº¦\n",
        "generate_config = types.GenerateContentConfig(\n",
        "    temperature=0.7,\n",
        "    top_p=0.95,\n",
        "    max_output_tokens=8192,\n",
        "\n",
        "    # ã€å…³é”®è®¾ç½®ã€‘å¯ç”¨æ·±åº¦æ€è€ƒæ¨¡å¼\n",
        "    # 'HIGH' é€‚åˆå¤æ‚é€»è¾‘/ç¼–ç¨‹ï¼Œ'LOW' é€‚åˆå¿«é€Ÿå¯¹è¯\n",
        "    # æ³¨æ„ï¼šè¿™æ˜¯ Gemini 3 / 2.0 Flash Thinking ç³»åˆ—ç‰¹æœ‰çš„å‚æ•°ç»“æ„\n",
        "    thinking_config=types.ThinkingConfig(\n",
        "        include_thoughts=True # è®©æ¨¡å‹è¿”å›å®ƒçš„æ€è€ƒè¿‡ç¨‹\n",
        "    )\n",
        ")\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 3. å®šä¹‰æç¤ºè¯\n",
        "# ---------------------------------------------------------\n",
        "prompt = \"\"\"\n",
        "è¯·åˆ†æä¸€ä¸‹ï¼šå¦‚æœäººç±»å®ç°äº†å¯æ§æ ¸èšå˜ï¼Œå¯¹å…¨çƒåœ°ç¼˜æ”¿æ²»æ ¼å±€ä¼šæœ‰å“ªäº›å…·ä½“çš„ã€åˆ†é˜¶æ®µçš„å½±å“ï¼Ÿ\n",
        "è¯·å…ˆè¿›è¡Œæ·±åº¦çš„æ€ç»´é“¾æ¨å¯¼ï¼Œç„¶åå†ç»™å‡ºæœ€ç»ˆç»“è®ºã€‚\n",
        "\"\"\"\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 4. è°ƒç”¨æ¨¡å‹ (ä½¿ç”¨æµå¼ä¼ è¾“ Stream)\n",
        "# ---------------------------------------------------------\n",
        "# è¿™é‡Œçš„æ¨¡å‹ ID æ˜¯æˆ‘ä»¬åœ¨ä¸Šæ–‡ä¸­è®¨è®ºçš„é¢„è§ˆç‰ˆ ID\n",
        "MODEL_ID = \"gemini-3-pro-preview\"\n",
        "\n",
        "# å¦‚æœä½ æ˜¯ 2024/2025 å¹´çš„ç”¨æˆ·ï¼Œè¯·å–æ¶ˆä¸‹é¢è¿™è¡Œçš„æ³¨é‡Šä»¥ä½¿ç”¨å½“æ—¶å¯ç”¨çš„æ¨¡å‹ï¼š\n",
        "# MODEL_ID = \"gemini-2.0-flash-thinking-exp\"\n",
        "\n",
        "print(f\"æ­£åœ¨è°ƒç”¨æ¨¡å‹: {MODEL_ID} ...\\n\")\n",
        "\n",
        "try:\n",
        "    response = client.models.generate_content_stream(\n",
        "        model=MODEL_ID,\n",
        "        contents=prompt,\n",
        "        config=generate_config\n",
        "    )\n",
        "\n",
        "    # ---------------------------------------------------------\n",
        "    # 5. å¤„ç†å¹¶æ˜¾ç¤ºæµå¼è¾“å‡º\n",
        "    # ---------------------------------------------------------\n",
        "    final_text = \"\"\n",
        "    print(\"--- å›ç­”å¼€å§‹ ---\\n\")\n",
        "\n",
        "    for chunk in response:\n",
        "        # æ£€æŸ¥æ˜¯å¦æœ‰æ–‡æœ¬å†…å®¹\n",
        "        if chunk.text:\n",
        "            print(chunk.text, end=\"\", flush=True)\n",
        "            final_text += chunk.text\n",
        "\n",
        "    # å¦‚æœå¼€å¯äº† include_thoughtsï¼Œé€šå¸¸ API ä¼šåœ¨å…ƒæ•°æ®æˆ–ç‰¹å®šå­—æ®µè¿”å›æ€è€ƒè¿‡ç¨‹\n",
        "    # è¿™é‡Œæ¼”ç¤ºç®€å•çš„æ–‡æœ¬æ¥æ”¶\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n\\nè°ƒç”¨å‡ºé”™: {e}\")\n",
        "    print(\"æç¤ºï¼šè¯·æ£€æŸ¥ä½ çš„ API Key æ˜¯å¦æœ‰æƒé™è®¿é—®è¯¥é¢„è§ˆç‰ˆæ¨¡å‹ã€‚\")"
      ],
      "metadata": {
        "id": "EbqcGAHz9xhr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## å£°éŸ³æå–å­—å¹•"
      ],
      "metadata": {
        "id": "oANIyxS4qbcb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# å®‰è£… openai-whisper\n",
        "!pip install git+https://github.com/openai/whisper.git -q\n",
        "\n",
        "# å®‰è£… ffmpeg (éŸ³é¢‘å¤„ç†å¿…é¡»)\n",
        "!sudo apt update && sudo apt install ffmpeg -q\n",
        "\n",
        "print(\"å®‰è£…å®Œæˆï¼è¯·ç»§ç»­ä¸‹ä¸€æ­¥ã€‚\")"
      ],
      "metadata": {
        "id": "TQ_Wg-AAqgFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "# æ¸…ç†æ—§æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰\n",
        "!rm -f *.mp3 *.wav *.m4a *.mp4\n",
        "\n",
        "print(\"è¯·ä¸Šä¼ éœ€è¦æå–å­—å¹•çš„éŸ³é¢‘/è§†é¢‘æ–‡ä»¶ï¼š\")\n",
        "uploaded = files.upload()\n",
        "file_name = list(uploaded.keys())[0]\n",
        "\n",
        "print(f\"å·²ä¸Šä¼ æ–‡ä»¶: {file_name}\")"
      ],
      "metadata": {
        "id": "SEE_XApmrPOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ä¸ºäº†å¤„ç†æ–‡ä»¶åä¸­çš„ç©ºæ ¼ï¼Œæˆ‘ä»¬å¯¹æ–‡ä»¶ååŠ å¼•å·\n",
        "import shlex\n",
        "\n",
        "safe_filename = shlex.quote(file_name)\n",
        "\n",
        "print(\"æ­£åœ¨æå–å­—å¹•ï¼Œè¯·è€å¿ƒç­‰å¾…ï¼ˆå–å†³äºæ–‡ä»¶æ—¶é•¿ï¼‰...\")\n",
        "# è¿è¡Œ Whisper\n",
        "# å‚æ•°è¯´æ˜ï¼š\n",
        "# --model large-v3 : ä½¿ç”¨æœ€æ–°çš„å¤§æ¨¡å‹ä»¥è·å¾—æœ€é«˜ç²¾åº¦\n",
        "# --output_format srt : ä»…è¾“å‡º srt å­—å¹•æ–‡ä»¶\n",
        "# --verbose False : å‡å°‘è¾“å‡ºæ—¥å¿—ï¼Œåªçœ‹ç»“æœ\n",
        "!whisper {safe_filename} --model large-v3 --output_format srt --verbose False\n",
        "\n",
        "print(\"æå–å®Œæˆï¼\")"
      ],
      "metadata": {
        "id": "POcpNk-JrWQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# è·å–ç”Ÿæˆçš„ srt æ–‡ä»¶åï¼ˆWhisper ä¼šç”Ÿæˆä¸åŸæ–‡ä»¶ååŒåçš„ .srt æ–‡ä»¶ï¼‰\n",
        "base_name = os.path.splitext(file_name)[0]\n",
        "srt_file = base_name + \".srt\"\n",
        "\n",
        "if os.path.exists(srt_file):\n",
        "    print(f\"æ‰¾åˆ°å­—å¹•æ–‡ä»¶: {srt_file}\\n\")\n",
        "\n",
        "    # æ‰“å°å‰10è¡Œé¢„è§ˆ\n",
        "    print(\"=== å­—å¹•é¢„è§ˆ (å‰10è¡Œ) ===\")\n",
        "    with open(srt_file, 'r', encoding='utf-8') as f:\n",
        "        print(\"\".join(f.readlines()[:10]))\n",
        "    print(\"========================\\n\")\n",
        "\n",
        "    # è‡ªåŠ¨ä¸‹è½½\n",
        "    files.download(srt_file)\n",
        "else:\n",
        "    print(\"æœªæ‰¾åˆ°å­—å¹•æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥ä¸Šä¸€æ­¥æ˜¯å¦æŠ¥é”™ã€‚\")"
      ],
      "metadata": {
        "id": "vkFRxxwvrm6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ä½¿ç”¨Qwen3å…‹éš†å£°éŸ³"
      ],
      "metadata": {
        "id": "WJq73eM-cbP7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# å®‰è£… Qwen-TTS æ ¸å¿ƒåº“åŠç›¸å…³ä¾èµ–\n",
        "!pip install -U qwen-tts transformers accelerate librosa soundfile\n",
        "# ä¸ºäº†æ›´å¿«çš„æ¨ç†é€Ÿåº¦ï¼ˆå¯é€‰ï¼ŒT4 GPU ç¼–è¯‘è¾ƒæ…¢ï¼‰\n",
        "# !pip install flash-attn --no-build-isolation"
      ],
      "metadata": {
        "id": "MZpqibpQch83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import soundfile as sf\n",
        "from qwen_tts import Qwen3TTSModel\n",
        "from google.colab import files\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "# 1. æ¨¡å‹é…ç½®\n",
        "# ä¹Ÿå¯ä»¥æ¢æˆ Qwen/Qwen3-TTS-12Hz-1.7B-Instruct (å¦‚æœæœ‰å¯¹è¯ç‰ˆ)\n",
        "model_id = \"Qwen/Qwen3-TTS-12Hz-1.7B-Base\"\n",
        "\n",
        "print(f\"æ­£åœ¨ä» Hugging Face åŠ è½½æ¨¡å‹: {model_id}...\")\n",
        "\n",
        "# 2. åŠ è½½æ¨¡å‹\n",
        "# æç¤ºï¼šT4 GPU æ˜¾å­˜çº¦ä¸º 15GBï¼Œ1.7B æ¨¡å‹åœ¨ bfloat16 ä¸‹çº¦å ç”¨ 4-5GB\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = Qwen3TTSModel.from_pretrained(\n",
        "    model_id,\n",
        "    device_map=device,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    # å¦‚æœæ²¡å®‰è£… flash-attnï¼Œè¯·ä¿æŒä½¿ç”¨ \"sdpa\"\n",
        "    attn_implementation=\"sdpa\"\n",
        ")\n",
        "\n",
        "# 3. ä¸Šä¼ å‚è€ƒéŸ³é¢‘ (Voice Prompt)\n",
        "print(\"\\n--- è¯·ä¸Šä¼ å‚è€ƒéŸ³é¢‘æ–‡ä»¶ (å»ºè®® 3-10 ç§’ï¼ŒWAV/MP3) ---\")\n",
        "uploaded = files.upload()\n",
        "if not uploaded:\n",
        "    raise ValueError(\"æœªä¸Šä¼ ä»»ä½•æ–‡ä»¶ï¼Œè¯·é‡æ–°è¿è¡Œæ­¤å•å…ƒæ ¼ã€‚\")\n",
        "\n",
        "ref_audio_path = list(uploaded.keys())[0]\n",
        "\n",
        "# 4. è®¾ç½®å‚æ•°\n",
        "# æ³¨æ„ï¼šæä¾›å‚è€ƒéŸ³é¢‘ä¸­çš„å‡†ç¡®æ–‡æœ¬æœ‰åŠ©äºæ¨¡å‹æ›´å¥½åœ°æ•æ‰éŸ³è‰²\n",
        "ref_text = input(\"è¯·è¾“å…¥å‚è€ƒéŸ³é¢‘ä¸­æ­£åœ¨è¯´çš„å†…å®¹ï¼ˆæ”¯æŒä¸­/è‹±/æ—¥ç­‰ï¼‰: \")\n",
        "target_text = input(\"è¯·è¾“å…¥ä½ æƒ³è¦åˆæˆçš„ç›®æ ‡æ–‡æœ¬: \")\n",
        "\n",
        "print(\"\\n--- æ­£åœ¨æ‰§è¡Œå£°éŸ³å…‹éš† ---\")\n",
        "\n",
        "# 5. æ‰§è¡Œæ¨ç†\n",
        "# ç¬¬ä¸€æ­¥ï¼šæå–éŸ³é¢‘ç‰¹å¾ä½œä¸º Prompt\n",
        "voice_clone_prompt = model.create_voice_clone_prompt(\n",
        "    ref_audio=ref_audio_path,\n",
        "    ref_text=ref_text\n",
        ")\n",
        "\n",
        "# ç¬¬äºŒæ­¥ï¼šæ ¹æ® Prompt ç”Ÿæˆç›®æ ‡è¯­éŸ³\n",
        "# è¯¥æ¨¡å‹æ”¯æŒä¸­ã€è‹±ã€æ—¥ã€éŸ©ã€å¾·ã€æ³•ã€æ„ã€ä¿„ã€è¥¿ã€è‘¡\n",
        "wavs, sr = model.generate_voice_clone(\n",
        "    text=target_text,\n",
        "    language=\"english\", # è¿™é‡Œå¯ä»¥æ ¹æ®éœ€è¦ä¿®æ”¹ç›®æ ‡è¯­è¨€\n",
        "    voice_clone_prompt=voice_clone_prompt\n",
        ")\n",
        "\n",
        "# 6. ä¿å­˜å¹¶æ’­æ”¾ç»“æœ\n",
        "output_filename = \"huggingface_output.wav\"\n",
        "sf.write(output_filename, wavs[0], sr)\n",
        "\n",
        "print(f\"\\nç”ŸæˆæˆåŠŸï¼å·²ä¿å­˜ä¸º: {output_filename}\")\n",
        "display(Audio(output_filename, autoplay=True))"
      ],
      "metadata": {
        "id": "mM3cSqmLxVoK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}